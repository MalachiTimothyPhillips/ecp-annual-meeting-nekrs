                 __    ____  _____
   ____   ___   / /__ / __ \/ ___/
  / __ \ / _ \ / //_// /_/ /\__ \ 
 / / / //  __// ,<  / _, _/___/ / 
/_/ /_/ \___//_/|_|/_/ |_|/____/  v21.1.1 (7d6ec9bc)

COPYRIGHT (c) 2019-2021 UCHICAGO ARGONNE, LLC

MPI tasks: 72

reading par file ...
general::filtering is deprecated and might be removed in the future!
general::filtermodes is deprecated and might be removed in the future!
general::filterweight is deprecated and might be removed in the future!

using NEKRS_HOME: /ccs/home/malachi/.local/nekrs-preco-auto
using NEKRS_CACHE_DIR: /gpfs/alpine/csc262/scratch/malachi/siam-pp-22/pb1568/auto-fp32-12/.cache
using OCCA_CACHE_DIR: /gpfs/alpine/csc262/scratch/malachi/siam-pp-22/pb1568/auto-fp32-12/.cache/occa/

Initializing device 
active occa mode: CUDA

building udf ... 
Consolidate compiler generated dependencies of target UDF
[100%] Built target UDF
done (0.66321s)
skip building nekInterface (SIZE has not changed)
loading nek ... 
done
loading udf kernels ... done (0.00606117s)

loading kernels ... done (3.39046s)

 Reading /gpfs/alpine/csc262/scratch/malachi/siam-pp-22/pb1568/auto-fp32-12/peb1568_n2t2bnb.re2                                              
 reading mesh 
 reading bc for ifld           1
 done :: read .re2 file     1.0     sec

Running parCon ... (tol=0.2)

 Error: elementCheck
Running parCon ... (tol=0.02)
Running parRSB ...
Warning: Partitioner only reached a tolerance of 1.280332 given 0.000500 after 50 x 50 iterations in Level=1!
parRSB finished in 5.02555 s

 reading mesh 
 reading curved sides 
 reading bc for ifld           1
 done :: read .re2 file     1.2     sec

 setup mesh topology
   Right-handed check complete for      524386 elements. OK.
gs_setup: 4530143 unique labels shared
   handle bytes (avg, min, max): 2.55966e+07 24947436 26204412
   buffer bytes (avg, min, max): 2.06179e+06 1428432 2694016
   setupds time 7.7286E-01 seconds   0  8    70904907      524386
 
 nElements   max/min/bal: 7284 7283 1.00
 nMessages   max/min/avg: 20 7 12.19
 msgSize     max/min/avg: 42392 1 10817.14
 msgSizeSum  max/min/avg: 168376 89277 128862.00
 
 max multiplicity           44
 done :: setup mesh topology
  
 call usrdat
 done :: usrdat

 generate geometry data
 done :: generate geometry data
  
 call usrdat2
 done :: usrdat2

  3.9629E-15  3.9299E-15  7.1054E-15  7.6927E-16  7.6927E-16  9.8206E-16 xyz repair 1
  3.9629E-15  3.9299E-15  7.1054E-15  6.9253E-15  6.5223E-15  9.3390E-15 xyz repair 2
  3.7848E-15  3.5527E-15  7.1054E-15  5.8127E-15  6.1523E-15  8.9797E-15 xyz repair 3
  3.7863E-15  2.8779E-15  3.2674E-15  3.7863E-15  2.8779E-15  3.2674E-15 xyz repair 4
 regenerate geometry data           1
 done :: regenerate geometry data           1
  
 regenerate geometry data           1
 done :: regenerate geometry data           1
  
 verify mesh topology
  -13.858251128023300        13.858078221547562       Xrange
  -13.858092645782323        13.858190303122345       Yrange
  -14.673319816589355        17.691219329833984       Zrange
 done :: verify mesh topology
  
 mesh metrics:
 GLL grid spacing min/max    : 2.21E-04 3.02E-01
 scaled Jacobian  min/max/avg: 2.59E-02 9.91E-01 3.71E-01
 aspect ratio     min/max/avg: 1.12E+00 1.08E+02 1.26E+01

 call usrdat3
 done :: usrdat3

gridpoints unique/tot:     184172283    268485632
dofs vel/pr:               175531272    184064426
 nek setup done in    1.4976E+01 s

 set initial conditions
 Checking restart options: r5.fld                                                                                                                              
 nekuic (1) for ifld            1
 Reading checkpoint data 
       FILE:/gpfs/alpine/csc262/scratch/malachi/siam-pp-22/pb1568/auto-fp32-12/r5.fld                                                           

        0  2.0000E+01 done :: Read checkpoint data
                              avg data-throughput =     2.0GB/s
                              io-nodes =    72

 xyz min    -13.858      -13.858      -14.673    
 uvwpt min  -6.4231      -7.8486      -7.9142      -20.893       0.0000    
 PS min      0.0000       0.0000       0.0000      0.99000E+22
 xyz max     13.858       13.858       17.691    
 uvwpt max   6.5953       7.1037       10.614       19.461       0.0000    
 PS max      0.0000       0.0000       0.0000     -0.99000E+22
 Restart: recompute geom. factors.
 regenerate geometry data           1
 done :: regenerate geometry data           1
  
 done :: set initial conditions
  
calling nek_userchk ...
 xyz min    -13.858      -13.858      -14.673    
 xyz max     13.858       13.858       17.691    

loading mesh from nek ... NboundaryIDs: 4, NboundaryFaces: 178458 done (0.00103977s)
generating mesh ... Nq: 8 cubNq: 11
computing geometric factors ... J [1.11222e-05,0.168148] done (0.418641s)
timing oogs modes: 0.000638118s 0.000424512s 0.000404982s 0.000416938s 0.000343648s 0.000281211s used config: 3.0.1
min 56% of the local elements are internal
timing oogs modes: 0.00210899s 0.00103346s 0.000984684s 0.000987891s 0.000738404s 0.000747664s used config: 3.0.0
loading ns kernels ... done (0.00273281s)
copying solution from nek
calling udf_setup ... done
================ ELLIPTIC SETUP VELOCITY ================
bID 1 -> bcType fixedValue
bID 2 -> bcType zeroGradient
bID 3 -> bcType zeroValue
bID 4 -> bcType zeroValue
allNeumann = 0 
loading elliptic kernels ... done (0.00017447s)
timing oogs modes: 0.0023673s 0.000981919s 0.000981958s 0.000975444s 0.000723993s 0.000740747s used config: 3.0.0
timing oogs modes: 0.00231388s 0.00165111s 0.00164813s 0.00165397s 0.00077442s 0.00107169s used config: 3.0.0
building Jacobi preconditioner ... done (0.311113s)
done (1.56544s)
================ ELLIPTIC SETUP PRESSURE ================
allNeumann = 0 
loading elliptic kernels ... done (0.00293095s)
timing oogs modes: 0.00063658s 0.00040111s 0.000413282s 0.00040474s 0.000334945s 0.000283736s used config: 3.0.1
timing oogs modes: 0.000659756s 0.000737933s 0.000750778s 0.000736891s 0.000407135s 0.000388091s used config: 3.0.1
building MG preconditioner ... 
loading elliptic preconditioner kernels ... done (0.000159357s)
=============BUILDING MULTIGRID LEVEL OF DEGREE 7==================
timing oogs modes: 0.000608144s 0.000268312s 0.000276744s 0.000276656s 0.000241398s 0.000211158s used config: 3.0.1
timing oogs modes: 0.000680515s 0.000414378s 0.000409665s 0.000417025s 0.000291812s 0.000275306s used config: 3.0.1
timing oogs modes: 0.00072302s 0.000321394s 0.000303917s 0.000310506s 0.000249597s 0.000214339s used config: 3.0.1
estimating maxEigenvalue ... 12.4543 done (0.549339s)
estimating maxEigenvalue ... 15.9638 done (0.129524s)
building Jacobi ... done (0.203569s)
estimating maxEigenvalue ... 3.60861 done (0.113398s)
=============BUILDING MULTIGRID LEVEL OF DEGREE 5==================
computing geometric factors ... J [1.11206e-05,0.168147] done (0.165339s)
loading elliptic preconditioner kernels ... done (0.000207232s)
done (0.000323211s)
timing oogs modes: 0.000405874s 0.000204912s 0.000197635s 0.000201909s 0.00021913s 0.000198628s used config: 2.0.1
timing oogs modes: 0.000406724s 0.000283291s 0.000285129s 0.000273767s 0.000246057s 0.000227276s used config: 3.0.1
timing oogs modes: 0.00045688s 0.000224503s 0.000220662s 0.000225187s 0.000195647s 0.000193718s used config: 3.0.1
estimating maxEigenvalue ... 9.30155 done (0.470734s)
estimating maxEigenvalue ... 12.4176 done (0.063829s)
building Jacobi ... done (0.0737446s)
estimating maxEigenvalue ... 3.0694 done (0.0565899s)
=============BUILDING MULTIGRID LEVEL OF DEGREE 3==================
computing geometric factors ... J [1.11284e-05,0.16815] done (0.045053s)
loading elliptic preconditioner kernels ... done (0.000195127s)
done (0.000315714s)
timing oogs modes: 0.000226301s 0.000150014s 0.000149912s 0.000146771s 0.000210349s 0.000189258s used config: 2.1.0
timing oogs modes: 0.000249613s 0.000193344s 0.000191424s 0.000194336s 0.000193201s 0.000217469s used config: 2.0.1
timing oogs modes: 0.000261614s 0.000170487s 0.000167607s 0.000166359s 0.00020288s 0.000182873s used config: 2.1.0
estimating maxEigenvalue ... 8.14536 done (0.035018s)
estimating maxEigenvalue ... 7.88893 done (0.0322542s)
building Jacobi ... done (0.0192984s)
estimating maxEigenvalue ... 2.41299 done (0.0290991s)
=============BUILDING MULTIGRID LEVEL OF DEGREE 1==================
computing geometric factors ... J [1.11737e-05,0.168688] done (0.00601362s)
loading elliptic preconditioner kernels ... done (0.000175378s)
done (0.000284097s)
timing oogs modes: 0.00013562s 0.000127819s 0.000127527s 0.000127128s 0.000203812s 0.000150919s used config: 2.1.0
timing oogs modes: 0.000162055s 0.000150387s 0.000148258s 0.000152553s 0.000222573s 0.000210116s used config: 2.0.1
building full FEM matrix ... done.
done (0.217553s)
Setting up AMG...

 Num MPI tasks = 72

 Num OpenMP threads = 1


BoomerAMG SETUP PARAMETERS:

 Max levels = 25
 Num levels = 8

 Strength Threshold = 0.250000
 Interpolation Truncation Factor = 0.000000
 Maximum Row Sum Threshold for Dependency Weakening = 0.900000

 Coarsening Type = PMIS 
 measures are determined locally

 Interpolation = extended+i interpolation

Operator Matrix Information:

             nonzero            entries/row          row sums
lev    rows  entries sparse   min  max     avg      min         max
======================================================================
  0  603488 10696902  0.000     8   91    17.7  -2.083e-07   2.251e+00
  1  260195  7223783  0.000     9  194    27.8  -2.151e-06   2.633e+00
  2   84577  2770253  0.000     7  185    32.8  -7.286e-03   3.039e+00
  3   18874   628292  0.002     9  138    33.3  -8.660e-03   5.086e+00
  4    3241   123531  0.012    12  134    38.1  -5.045e-03   7.308e+00
  5     395    14179  0.091    11  112    35.9  -3.054e-03   9.432e+00
  6      43     1003  0.542    11   39    23.3  -2.421e-04   1.594e+01
  7       3        9  1.000     3    3     3.0   3.142e+00   1.531e+01


Interpolation Matrix Information:
                      entries/row        min        max            row sums
lev   rows x cols   min  max  avgW     weight      weight       min         max
==================================================================================
  0 603488 x 260195   1    4   2.1  -1.977e-01   1.000e+00   5.309e-01   1.000e+00
  1 260195 x 84577    1    4   3.1  -1.044e-01   1.011e+00   3.734e-01   1.000e+00
  2  84577 x 18874    1    4   3.7  -2.124e-01   1.005e+00   2.891e-01   1.005e+00
  3  18874 x 3241     1    4   3.9  -7.892e-01   1.005e+00   1.977e-01   1.018e+00
  4   3241 x 395      1    4   4.0  -9.538e-02   8.330e-01   1.197e-01   1.006e+00
  5    395 x 43       1    4   4.0   1.500e-02   7.648e-01   1.618e-01   1.004e+00
  6     43 x 3        1    3   2.8  -1.597e-01   9.136e-01   5.774e-02   1.000e+00


     Complexity:    grid = 1.608675
                operator = 2.005997
                memory = 2.187492




BoomerAMG SOLVER PARAMETERS:

  Maximum number of cycles:         1 
  Stopping Tolerance:               0.000000e+00 
  Cycle type (1 = V, 2 = W, etc.):  1

  Relaxation Parameters:
   Visiting Grid:                     down   up  coarse
            Number of sweeps:            1    1     1 
   Type 0=Jac, 3=hGS, 6=hSGS, 9=GE:     16   16     9 
   Point types, partial sweeps (1=C, -1=F):
                  Pre-CG relaxation (down):   0
                   Post-CG relaxation (up):   0
                             Coarsest grid:   0

done (0.281956s)
--------------------Multigrid Report---------------------
---------------------------------------------------------
level|    Type    |                 |     Smoother      |
     |            |                 |                   |
---------------------------------------------------------
   0 |    pMG     |   Matrix-free   | Chebyshev+ASM     |
     |            |     Degree  7   |                   |
   1 |    pMG     |   Matrix-free   | Chebyshev+ASM     |
     |            |     Degree  5   |                   |
   2 |    pMG     |   Matrix-free   | Chebyshev+ASM     |
     |            |     Degree  3   |                   |
   3 |    AMG     |   Matrix        | BoomerAMG         |
     |            |     Degree  1   |                   |
---------------------------------------------------------
done (34.6212s)
done (38.7479s)
copying solution to nek

settings:

key: CHECKPOINT OUTPUT MESH,                                  value: FALSE
key: FORMAT,                                                  value: 1.0
key: CONSTANT FLOW RATE,                                      value: FALSE
key: ELEMENT TYPE,                                            value: 12
key: ELEMENT MAP,                                             value: ISOPARAMETRIC
key: MESH DIMENSION,                                          value: 3
key: NUMBER OF SCALARS,                                       value: 0
key: SCALAR MAXIMUM ITERATIONS,                               value: 200
key: TIME INTEGRATOR,                                         value: TOMBO2
key: MESH INTEGRATION ORDER,                                  value: 3
key: SUBCYCLING STEPS,                                        value: 2
key: SUBCYCLING TIME ORDER,                                   value: 4
key: SUBCYCLING TIME STAGE NUMBER,                            value: 4
key: CASENAME,                                                value: peb1568_n2t2bnb
key: UDF OKL FILE,                                            value: peb1568_n2t2bnb.oudf
key: UDF FILE,                                                value: peb1568_n2t2bnb.udf
key: NEK USR FILE,                                            value: peb1568_n2t2bnb.usr
key: MESH FILE,                                               value: peb1568_n2t2bnb.re2
key: DEVICE NUMBER,                                           value: 0
key: PLATFORM NUMBER,                                         value: 0
key: VERBOSE,                                                 value: FALSE
key: ADVECTION,                                               value: TRUE
key: ADVECTION TYPE,                                          value: CUBATURE+CONVECTIVE
key: RESTART FROM FILE,                                       value: 1
key: SOLUTION OUTPUT INTERVAL,                                value: 0.000000
key: SOLUTION OUTPUT CONTROL,                                 value: STEPS
key: REGULARIZATION METHOD,                                   value: RELAXATION
key: START TIME,                                              value: 2.000000e+01
key: VELOCITY MAXIMUM ITERATIONS,                             value: 200
key: VELOCITY BLOCK SOLVER,                                   value: TRUE
key: VELOCITY KRYLOV SOLVER,                                  value: PCG
key: VELOCITY BASIS,                                          value: NODAL
key: VELOCITY PRECONDITIONER,                                 value: JACOBI
key: VELOCITY DISCRETIZATION,                                 value: CONTINUOUS
key: STRESSFORMULATION,                                       value: FALSE
key: ELLIPTIC INTEGRATION,                                    value: NODAL
key: PRESSURE MAXIMUM ITERATIONS,                             value: 200
key: GALERKIN COARSE MATRIX,                                  value: FALSE
key: PRESSURE KRYLOV SOLVER,                                  value: PGMRES+FLEXIBLE
key: PRESSURE PRECONDITIONER,                                 value: MULTIGRID
key: PRESSURE DISCRETIZATION,                                 value: CONTINUOUS
key: PRESSURE AUTO PRECONDITIONER,                            value: TRUE
key: PRESSURE BASIS,                                          value: NODAL
key: AMG SOLVER,                                              value: BOOMERAMG
key: AMG SOLVER PRECISION,                                    value: FP64
key: AMG SOLVER LOCATION,                                     value: CPU
key: PRESSURE PARALMOND CYCLE,                                value: VCYCLE
key: PRESSURE MULTIGRID COARSE SOLVE,                         value: TRUE
key: PRESSURE MULTIGRID COARSE SEMFEM,                        value: FALSE
key: PRESSURE MULTIGRID SMOOTHER,                             value: CHEBYSHEV+ASM
key: PRESSURE MULTIGRID CHEBYSHEV DEGREE,                     value: 2
key: PRESSURE MULTIGRID CHEBYSHEV MIN EIGENVALUE BOUND FACTOR,value: 0.1
key: PRESSURE MULTIGRID CHEBYSHEV MAX EIGENVALUE BOUND FACTOR,value: 1.1
key: PRESSURE INITIAL GUESS,                                  value: PROJECTION-ACONJ
key: PRESSURE RESIDUAL PROJECTION VECTORS,                    value: 10
key: PRESSURE RESIDUAL PROJECTION START,                      value: 5
key: PARALMOND SMOOTH COARSEST,                               value: FALSE
key: ENABLE FLOATCOMMHALF GS SUPPORT,                         value: FALSE
key: MOVING MESH,                                             value: FALSE
key: ENABLE OVERLAP,                                          value: TRUE
key: VARIABLE DT,                                             value: FALSE
key: THREAD MODEL,                                            value: CUDA
key: RESTART FILE NAME,                                       value: r5.fld
key: POLYNOMIAL DEGREE,                                       value: 7
key: DT,                                                      value: 5.000000e-04
key: NUMBER TIMESTEPS,                                        value: 2000
key: CUBATURE POLYNOMIAL DEGREE,                              value: 10
key: HPFRT STRENGTH,                                          value: 2.000000e+02
key: HPFRT MODES,                                             value: 2.000000e+00
key: VELOCITY REGULARIZATION METHOD,                          value: RELAXATION
key: VELOCITY HPFRT MODES,                                    value: 2.000000e+00
key: VELOCITY HPFRT STRENGTH,                                 value: 2.000000e+02
key: PRESSURE SOLVER TOLERANCE,                               value: 1.000000e-04
key: PRESSURE AUTO PRECONDITIONER TRIAL FREQUENCY,            value: 5000
key: PRESSURE AUTO PRECONDITIONER START,                      value: 100
key: PRESSURE AUTO PRECONDITIONER MAX CHEBY ORDER,            value: 3
key: PRESSURE AUTO PRECONDITIONER MIN CHEBY ORDER,            value: 1
key: PRESSURE AUTO PRECONDITIONER NUM SAMPLES,                value: 3
key: PRESSURE SEMFEM SOLVER,                                  value: BOOMERAMG
key: VELOCITY SOLVER TOLERANCE,                               value: 1.000000e-06
key: DENSITY,                                                 value: 1.000000e+00
key: VISCOSITY,                                               value: 1.000000e-04
key: BUILD ONLY,                                              value: FALSE
key: DATA FILE,                                               value: /gpfs/alpine/csc262/scratch/malachi/siam-pp-22/pb1568/auto-fp32-12/.cache/udf/udf.okl
key: CI-MODE,                                                 value: 0

occa memory usage: 6.60361 GB
initialization took 73.7867 s

timestepping for 2000 steps ...
  P  : iter 012  resNorm00 1.21e+00  resNorm0 1.21e+00  resNorm 6.45e-05
  UVW: iter 003  resNorm00 1.17e-01  resNorm0 1.17e-01  resNorm 4.27e-07  divErrNorms 9.76e-07 4.95e-01
step= 1  t= 2.00005000e+01  dt=5.0e-04  C= 2.05  UVW: 3  P: 12  eTimeStep= 1.55e+00s eTime= 1.54685e+00s
  P  : iter 014  resNorm00 1.50e+00  resNorm0 1.50e+00  resNorm 6.11e-05
  UVW: iter 003  resNorm00 1.76e-01  resNorm0 1.76e-01  resNorm 2.10e-07  divErrNorms 9.17e-07 4.93e-01
step= 2  t= 2.00010000e+01  dt=5.0e-04  C= 1.98  UVW: 3  P: 14  eTimeStep= 6.85e-01s eTime= 2.23210e+00s
  P  : iter 011  resNorm00 3.99e-01  resNorm0 3.99e-01  resNorm 7.99e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.09e-07  divErrNorms 8.65e-07 4.90e-01
step= 3  t= 2.00015000e+01  dt=5.0e-04  C= 1.93  UVW: 3  P: 11  eTimeStep= 5.13e-01s eTime= 2.74465e+00s
  P  : iter 010  resNorm00 2.17e-01  resNorm0 2.17e-01  resNorm 7.44e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.08e-07  divErrNorms 8.24e-07 4.87e-01
step= 4  t= 2.00020000e+01  dt=5.0e-04  C= 1.97  UVW: 3  P: 10  eTimeStep= 4.70e-01s eTime= 3.21424e+00s
  P  : iter 009  resNorm00 1.71e-01  resNorm0 1.71e-01  resNorm 8.87e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.07e-07  divErrNorms 7.89e-07 4.85e-01
step= 5  t= 2.00025000e+01  dt=5.0e-04  C= 1.98  UVW: 3  P: 9  eTimeStep= 4.34e-01s eTime= 3.64780e+00s
  P  : iter 007  resNorm00 1.54e-01  resNorm0 3.45e-02  resNorm 9.09e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.07e-07  divErrNorms 7.60e-07 4.83e-01
step= 6  t= 2.00030000e+01  dt=5.0e-04  C= 1.98  UVW: 3  P: 7  eTimeStep= 3.49e-01s eTime= 3.99677e+00s
  P  : iter 006  resNorm00 1.47e-01  resNorm0 1.44e-02  resNorm 8.50e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.06e-07  divErrNorms 7.36e-07 4.82e-01
step= 7  t= 2.00035000e+01  dt=5.0e-04  C= 1.97  UVW: 3  P: 6  eTimeStep= 3.16e-01s eTime= 4.31236e+00s
  P  : iter 005  resNorm00 1.43e-01  resNorm0 6.75e-03  resNorm 8.55e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.06e-07  divErrNorms 7.14e-07 4.81e-01
step= 8  t= 2.00040000e+01  dt=5.0e-04  C= 1.94  UVW: 3  P: 5  eTimeStep= 2.58e-01s eTime= 4.57064e+00s
  P  : iter 005  resNorm00 1.41e-01  resNorm0 3.49e-03  resNorm 6.75e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.06e-07  divErrNorms 6.95e-07 4.80e-01
step= 9  t= 2.00045000e+01  dt=5.0e-04  C= 1.89  UVW: 3  P: 5  eTimeStep= 2.80e-01s eTime= 4.85093e+00s
  P  : iter 005  resNorm00 1.40e-01  resNorm0 1.58e-03  resNorm 5.78e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 6.78e-07 4.79e-01
step= 10  t= 2.00050000e+01  dt=5.0e-04  C= 1.83  UVW: 3  P: 5  eTimeStep= 2.75e-01s eTime= 5.12635e+00s
  P  : iter 005  resNorm00 1.39e-01  resNorm0 1.08e-03  resNorm 5.12e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 6.62e-07 4.78e-01
step= 11  t= 2.00055000e+01  dt=5.0e-04  C= 1.76  UVW: 3  P: 5  eTimeStep= 2.71e-01s eTime= 5.39728e+00s
  P  : iter 005  resNorm00 1.38e-01  resNorm0 9.15e-04  resNorm 6.16e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 6.48e-07 4.77e-01
step= 12  t= 2.00060000e+01  dt=5.0e-04  C= 1.69  UVW: 3  P: 5  eTimeStep= 2.89e-01s eTime= 5.68599e+00s
  P  : iter 005  resNorm00 1.38e-01  resNorm0 7.76e-04  resNorm 5.26e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 6.34e-07 4.77e-01
step= 13  t= 2.00065000e+01  dt=5.0e-04  C= 1.74  UVW: 3  P: 5  eTimeStep= 2.81e-01s eTime= 5.96650e+00s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 7.36e-04  resNorm 6.16e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 6.22e-07 4.76e-01
step= 14  t= 2.00070000e+01  dt=5.0e-04  C= 1.79  UVW: 3  P: 5  eTimeStep= 2.73e-01s eTime= 6.23971e+00s
  P  : iter 004  resNorm00 1.37e-01  resNorm0 6.84e-04  resNorm 9.59e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 6.10e-07 4.76e-01
step= 15  t= 2.00075000e+01  dt=5.0e-04  C= 1.82  UVW: 3  P: 4  eTimeStep= 2.37e-01s eTime= 6.47721e+00s
  P  : iter 006  resNorm00 1.37e-01  resNorm0 8.01e-03  resNorm 6.82e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 5.98e-07 4.76e-01
step= 16  t= 2.00080000e+01  dt=5.0e-04  C= 1.86  UVW: 3  P: 6  eTimeStep= 3.19e-01s eTime= 6.79604e+00s
  P  : iter 004  resNorm00 1.37e-01  resNorm0 1.04e-03  resNorm 9.63e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 5.88e-07 4.75e-01
step= 17  t= 2.00085000e+01  dt=5.0e-04  C= 1.91  UVW: 3  P: 4  eTimeStep= 2.38e-01s eTime= 7.03442e+00s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 9.82e-04  resNorm 8.79e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 5.77e-07 4.75e-01
step= 18  t= 2.00090000e+01  dt=5.0e-04  C= 1.95  UVW: 3  P: 5  eTimeStep= 2.66e-01s eTime= 7.30033e+00s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 7.49e-04  resNorm 6.13e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 5.67e-07 4.75e-01
step= 19  t= 2.00095000e+01  dt=5.0e-04  C= 1.99  UVW: 3  P: 5  eTimeStep= 2.82e-01s eTime= 7.58247e+00s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 7.36e-04  resNorm 7.33e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 5.57e-07 4.75e-01
step= 20  t= 2.00100000e+01  dt=5.0e-04  C= 2.08  UVW: 3  P: 5  eTimeStep= 2.73e-01s eTime= 7.85557e+00s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 7.40e-04  resNorm 7.51e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 5.48e-07 4.75e-01
step= 21  t= 2.00105000e+01  dt=5.0e-04  C= 2.24  UVW: 3  P: 5  eTimeStep= 2.74e-01s eTime= 8.12951e+00s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 7.64e-04  resNorm 8.61e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 5.38e-07 4.75e-01
step= 22  t= 2.00110000e+01  dt=5.0e-04  C= 2.34  UVW: 3  P: 5  eTimeStep= 2.76e-01s eTime= 8.40597e+00s
  P  : iter 004  resNorm00 1.37e-01  resNorm0 7.28e-04  resNorm 9.20e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 5.29e-07 4.74e-01
step= 23  t= 2.00115000e+01  dt=5.0e-04  C= 2.39  UVW: 3  P: 4  eTimeStep= 2.48e-01s eTime= 8.65372e+00s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 8.48e-04  resNorm 6.50e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 5.20e-07 4.74e-01
step= 24  t= 2.00120000e+01  dt=5.0e-04  C= 2.37  UVW: 3  P: 5  eTimeStep= 2.78e-01s eTime= 8.93179e+00s
  P  : iter 004  resNorm00 1.37e-01  resNorm0 6.99e-04  resNorm 8.41e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 5.11e-07 4.74e-01
step= 25  t= 2.00125000e+01  dt=5.0e-04  C= 2.30  UVW: 3  P: 4  eTimeStep= 2.42e-01s eTime= 9.17372e+00s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 8.00e-03  resNorm 8.98e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 5.03e-07 4.74e-01
step= 26  t= 2.00130000e+01  dt=5.0e-04  C= 2.17  UVW: 3  P: 5  eTimeStep= 2.76e-01s eTime= 9.45005e+00s
  P  : iter 004  resNorm00 1.36e-01  resNorm0 9.29e-04  resNorm 6.50e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 4.94e-07 4.74e-01
step= 27  t= 2.00135000e+01  dt=5.0e-04  C= 2.02  UVW: 3  P: 4  eTimeStep= 2.30e-01s eTime= 9.68001e+00s
  P  : iter 005  resNorm00 1.36e-01  resNorm0 8.81e-04  resNorm 7.26e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 4.85e-07 4.74e-01
step= 28  t= 2.00140000e+01  dt=5.0e-04  C= 2.00  UVW: 3  P: 5  eTimeStep= 2.64e-01s eTime= 9.94410e+00s
  P  : iter 005  resNorm00 1.36e-01  resNorm0 6.35e-04  resNorm 5.59e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 4.77e-07 4.74e-01
step= 29  t= 2.00145000e+01  dt=5.0e-04  C= 1.98  UVW: 3  P: 5  eTimeStep= 2.69e-01s eTime= 1.02133e+01s
  P  : iter 005  resNorm00 1.36e-01  resNorm0 6.91e-04  resNorm 7.65e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 4.68e-07 4.74e-01
step= 30  t= 2.00150000e+01  dt=5.0e-04  C= 1.96  UVW: 3  P: 5  eTimeStep= 2.78e-01s eTime= 1.04909e+01s
  P  : iter 005  resNorm00 1.36e-01  resNorm0 7.55e-04  resNorm 7.82e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 4.60e-07 4.74e-01
step= 31  t= 2.00155000e+01  dt=5.0e-04  C= 1.93  UVW: 3  P: 5  eTimeStep= 2.76e-01s eTime= 1.07671e+01s
  P  : iter 006  resNorm00 1.36e-01  resNorm0 7.97e-04  resNorm 6.09e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 4.52e-07 4.74e-01
step= 32  t= 2.00160000e+01  dt=5.0e-04  C= 1.90  UVW: 3  P: 6  eTimeStep= 3.18e-01s eTime= 1.10850e+01s
  P  : iter 004  resNorm00 1.36e-01  resNorm0 7.16e-04  resNorm 9.99e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 4.43e-07 4.74e-01
step= 33  t= 2.00165000e+01  dt=5.0e-04  C= 1.87  UVW: 3  P: 4  eTimeStep= 2.36e-01s eTime= 1.13209e+01s
  P  : iter 004  resNorm00 1.36e-01  resNorm0 8.08e-04  resNorm 9.84e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 4.35e-07 4.74e-01
step= 34  t= 2.00170000e+01  dt=5.0e-04  C= 1.86  UVW: 3  P: 4  eTimeStep= 2.40e-01s eTime= 1.15608e+01s
  P  : iter 005  resNorm00 1.36e-01  resNorm0 9.37e-04  resNorm 6.39e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 4.27e-07 4.74e-01
step= 35  t= 2.00175000e+01  dt=5.0e-04  C= 2.02  UVW: 3  P: 5  eTimeStep= 2.75e-01s eTime= 1.18360e+01s
  P  : iter 006  resNorm00 1.36e-01  resNorm0 8.03e-03  resNorm 7.25e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 4.18e-07 4.74e-01
step= 36  t= 2.00180000e+01  dt=5.0e-04  C= 2.22  UVW: 3  P: 6  eTimeStep= 3.10e-01s eTime= 1.21457e+01s
  P  : iter 004  resNorm00 1.36e-01  resNorm0 1.02e-03  resNorm 8.37e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 4.10e-07 4.74e-01
step= 37  t= 2.00185000e+01  dt=5.0e-04  C= 2.34  UVW: 3  P: 4  eTimeStep= 2.23e-01s eTime= 1.23686e+01s
  P  : iter 005  resNorm00 1.36e-01  resNorm0 9.87e-04  resNorm 8.51e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 4.02e-07 4.74e-01
step= 38  t= 2.00190000e+01  dt=5.0e-04  C= 2.46  UVW: 3  P: 5  eTimeStep= 2.84e-01s eTime= 1.26528e+01s
  P  : iter 005  resNorm00 1.36e-01  resNorm0 9.01e-04  resNorm 8.26e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 3.94e-07 4.74e-01
step= 39  t= 2.00195000e+01  dt=5.0e-04  C= 2.58  UVW: 3  P: 5  eTimeStep= 2.79e-01s eTime= 1.29322e+01s
  P  : iter 005  resNorm00 1.36e-01  resNorm0 9.23e-04  resNorm 7.99e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 3.85e-07 4.74e-01
step= 40  t= 2.00200000e+01  dt=5.0e-04  C= 2.64  UVW: 3  P: 5  eTimeStep= 2.78e-01s eTime= 1.32103e+01s
  P  : iter 006  resNorm00 1.37e-01  resNorm0 9.81e-04  resNorm 5.85e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.05e-07  divErrNorms 3.77e-07 4.74e-01
step= 41  t= 2.00205000e+01  dt=5.0e-04  C= 2.62  UVW: 3  P: 6  eTimeStep= 3.14e-01s eTime= 1.35244e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 8.72e-04  resNorm 8.01e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.06e-07  divErrNorms 3.69e-07 4.74e-01
step= 42  t= 2.00210000e+01  dt=5.0e-04  C= 2.55  UVW: 3  P: 5  eTimeStep= 2.71e-01s eTime= 1.37959e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 8.80e-04  resNorm 8.86e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.06e-07  divErrNorms 3.61e-07 4.74e-01
step= 43  t= 2.00215000e+01  dt=5.0e-04  C= 2.47  UVW: 3  P: 5  eTimeStep= 2.77e-01s eTime= 1.40728e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 8.91e-04  resNorm 8.07e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.06e-07  divErrNorms 3.53e-07 4.74e-01
step= 44  t= 2.00220000e+01  dt=5.0e-04  C= 2.47  UVW: 3  P: 5  eTimeStep= 2.80e-01s eTime= 1.43526e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 7.74e-04  resNorm 6.50e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.06e-07  divErrNorms 3.44e-07 4.74e-01
step= 45  t= 2.00225000e+01  dt=5.0e-04  C= 2.43  UVW: 3  P: 5  eTimeStep= 2.82e-01s eTime= 1.46344e+01s
  P  : iter 006  resNorm00 1.37e-01  resNorm0 8.07e-03  resNorm 7.30e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.06e-07  divErrNorms 3.36e-07 4.74e-01
step= 46  t= 2.00230000e+01  dt=5.0e-04  C= 2.36  UVW: 3  P: 6  eTimeStep= 3.00e-01s eTime= 1.49341e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 9.79e-04  resNorm 6.60e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.06e-07  divErrNorms 3.28e-07 4.74e-01
step= 47  t= 2.00235000e+01  dt=5.0e-04  C= 2.25  UVW: 3  P: 5  eTimeStep= 2.74e-01s eTime= 1.52083e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 9.10e-04  resNorm 7.44e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.06e-07  divErrNorms 3.20e-07 4.74e-01
step= 48  t= 2.00240000e+01  dt=5.0e-04  C= 2.13  UVW: 3  P: 5  eTimeStep= 2.80e-01s eTime= 1.54884e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 7.00e-04  resNorm 7.30e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.06e-07  divErrNorms 3.12e-07 4.74e-01
step= 49  t= 2.00245000e+01  dt=5.0e-04  C= 1.99  UVW: 3  P: 5  eTimeStep= 2.79e-01s eTime= 1.57679e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 6.52e-04  resNorm 6.57e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.06e-07  divErrNorms 3.04e-07 4.74e-01
step= 50  t= 2.00250000e+01  dt=5.0e-04  C= 1.97  UVW: 3  P: 5  eTimeStep= 2.70e-01s eTime= 1.60378e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 7.70e-04  resNorm 9.32e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.06e-07  divErrNorms 2.96e-07 4.74e-01
step= 51  t= 2.00255000e+01  dt=5.0e-04  C= 1.98  UVW: 3  P: 5  eTimeStep= 2.82e-01s eTime= 1.63200e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 7.73e-04  resNorm 7.95e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.06e-07  divErrNorms 2.88e-07 4.74e-01
step= 52  t= 2.00260000e+01  dt=5.0e-04  C= 1.98  UVW: 3  P: 5  eTimeStep= 2.69e-01s eTime= 1.65887e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 7.34e-04  resNorm 8.43e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.06e-07  divErrNorms 2.79e-07 4.74e-01
step= 53  t= 2.00265000e+01  dt=5.0e-04  C= 1.98  UVW: 3  P: 5  eTimeStep= 2.52e-01s eTime= 1.68404e+01s
  P  : iter 004  resNorm00 1.37e-01  resNorm0 6.58e-04  resNorm 7.77e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.06e-07  divErrNorms 2.71e-07 4.74e-01
step= 54  t= 2.00270000e+01  dt=5.0e-04  C= 1.96  UVW: 3  P: 4  eTimeStep= 2.18e-01s eTime= 1.70581e+01s
  P  : iter 004  resNorm00 1.37e-01  resNorm0 6.61e-04  resNorm 9.80e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.07e-07  divErrNorms 2.63e-07 4.74e-01
step= 55  t= 2.00275000e+01  dt=5.0e-04  C= 1.94  UVW: 3  P: 4  eTimeStep= 2.17e-01s eTime= 1.72752e+01s
  P  : iter 006  resNorm00 1.37e-01  resNorm0 8.08e-03  resNorm 7.49e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.07e-07  divErrNorms 2.55e-07 4.74e-01
step= 56  t= 2.00280000e+01  dt=5.0e-04  C= 1.95  UVW: 3  P: 6  eTimeStep= 2.86e-01s eTime= 1.75613e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 1.02e-03  resNorm 7.83e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.07e-07  divErrNorms 2.47e-07 4.74e-01
step= 57  t= 2.00285000e+01  dt=5.0e-04  C= 1.98  UVW: 3  P: 5  eTimeStep= 2.51e-01s eTime= 1.78124e+01s
  P  : iter 004  resNorm00 1.37e-01  resNorm0 9.95e-04  resNorm 8.90e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.07e-07  divErrNorms 2.39e-07 4.74e-01
step= 58  t= 2.00290000e+01  dt=5.0e-04  C= 2.00  UVW: 3  P: 4  eTimeStep= 2.17e-01s eTime= 1.80294e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 7.68e-04  resNorm 6.86e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.07e-07  divErrNorms 2.31e-07 4.74e-01
step= 59  t= 2.00295000e+01  dt=5.0e-04  C= 2.02  UVW: 3  P: 5  eTimeStep= 2.51e-01s eTime= 1.82802e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 8.36e-04  resNorm 6.76e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.07e-07  divErrNorms 2.23e-07 4.74e-01
step= 60  t= 2.00300000e+01  dt=5.0e-04  C= 2.03  UVW: 3  P: 5  eTimeStep= 2.52e-01s eTime= 1.85323e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 8.60e-04  resNorm 8.61e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.07e-07  divErrNorms 2.15e-07 4.74e-01
step= 61  t= 2.00305000e+01  dt=5.0e-04  C= 2.03  UVW: 3  P: 5  eTimeStep= 2.51e-01s eTime= 1.87835e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 8.56e-04  resNorm 8.84e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.07e-07  divErrNorms 2.07e-07 4.74e-01
step= 62  t= 2.00310000e+01  dt=5.0e-04  C= 2.04  UVW: 3  P: 5  eTimeStep= 2.52e-01s eTime= 1.90357e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 8.14e-04  resNorm 9.67e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.07e-07  divErrNorms 1.99e-07 4.74e-01
step= 63  t= 2.00315000e+01  dt=5.0e-04  C= 2.03  UVW: 3  P: 5  eTimeStep= 2.54e-01s eTime= 1.92893e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 8.09e-04  resNorm 6.73e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.07e-07  divErrNorms 1.91e-07 4.74e-01
step= 64  t= 2.00320000e+01  dt=5.0e-04  C= 2.03  UVW: 3  P: 5  eTimeStep= 2.55e-01s eTime= 1.95439e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 8.24e-04  resNorm 7.37e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.07e-07  divErrNorms 1.83e-07 4.74e-01
step= 65  t= 2.00325000e+01  dt=5.0e-04  C= 2.02  UVW: 3  P: 5  eTimeStep= 2.51e-01s eTime= 1.97954e+01s
  P  : iter 006  resNorm00 1.37e-01  resNorm0 8.13e-03  resNorm 6.95e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.07e-07  divErrNorms 1.75e-07 4.74e-01
step= 66  t= 2.00330000e+01  dt=5.0e-04  C= 2.01  UVW: 3  P: 6  eTimeStep= 3.14e-01s eTime= 2.01097e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 1.10e-03  resNorm 6.82e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.07e-07  divErrNorms 1.67e-07 4.74e-01
step= 67  t= 2.00335000e+01  dt=5.0e-04  C= 2.01  UVW: 3  P: 5  eTimeStep= 2.67e-01s eTime= 2.03771e+01s
  P  : iter 004  resNorm00 1.37e-01  resNorm0 9.69e-04  resNorm 9.61e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.07e-07  divErrNorms 1.59e-07 4.74e-01
step= 68  t= 2.00340000e+01  dt=5.0e-04  C= 2.01  UVW: 3  P: 4  eTimeStep= 2.36e-01s eTime= 2.06128e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 8.91e-04  resNorm 7.27e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.08e-07  divErrNorms 1.52e-07 4.74e-01
step= 69  t= 2.00345000e+01  dt=5.0e-04  C= 2.00  UVW: 3  P: 5  eTimeStep= 2.63e-01s eTime= 2.08754e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 9.38e-04  resNorm 8.60e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.08e-07  divErrNorms 1.44e-07 4.74e-01
step= 70  t= 2.00350000e+01  dt=5.0e-04  C= 1.99  UVW: 3  P: 5  eTimeStep= 2.69e-01s eTime= 2.11442e+01s
  P  : iter 006  resNorm00 1.37e-01  resNorm0 1.03e-03  resNorm 6.69e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.08e-07  divErrNorms 1.36e-07 4.74e-01
step= 71  t= 2.00355000e+01  dt=5.0e-04  C= 1.99  UVW: 3  P: 6  eTimeStep= 3.13e-01s eTime= 2.14572e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 1.00e-03  resNorm 8.72e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.08e-07  divErrNorms 1.28e-07 4.74e-01
step= 72  t= 2.00360000e+01  dt=5.0e-04  C= 2.00  UVW: 3  P: 5  eTimeStep= 2.72e-01s eTime= 2.17287e+01s
  P  : iter 006  resNorm00 1.37e-01  resNorm0 1.11e-03  resNorm 6.60e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.08e-07  divErrNorms 1.20e-07 4.74e-01
step= 73  t= 2.00365000e+01  dt=5.0e-04  C= 2.00  UVW: 3  P: 6  eTimeStep= 3.16e-01s eTime= 2.20444e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 1.05e-03  resNorm 9.70e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.08e-07  divErrNorms 1.13e-07 4.74e-01
step= 74  t= 2.00370000e+01  dt=5.0e-04  C= 1.98  UVW: 3  P: 5  eTimeStep= 2.81e-01s eTime= 2.23255e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 1.03e-03  resNorm 7.64e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.08e-07  divErrNorms 1.05e-07 4.74e-01
step= 75  t= 2.00375000e+01  dt=5.0e-04  C= 1.95  UVW: 3  P: 5  eTimeStep= 2.75e-01s eTime= 2.26007e+01s
  P  : iter 006  resNorm00 1.37e-01  resNorm0 8.15e-03  resNorm 7.69e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.08e-07  divErrNorms 9.72e-08 4.74e-01
step= 76  t= 2.00380000e+01  dt=5.0e-04  C= 1.90  UVW: 3  P: 6  eTimeStep= 3.24e-01s eTime= 2.29243e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 1.13e-03  resNorm 6.25e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.08e-07  divErrNorms 8.96e-08 4.74e-01
step= 77  t= 2.00385000e+01  dt=5.0e-04  C= 1.86  UVW: 3  P: 5  eTimeStep= 2.70e-01s eTime= 2.31940e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 9.58e-04  resNorm 9.46e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.08e-07  divErrNorms 8.20e-08 4.74e-01
step= 78  t= 2.00390000e+01  dt=5.0e-04  C= 1.83  UVW: 3  P: 5  eTimeStep= 2.67e-01s eTime= 2.34607e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 8.30e-04  resNorm 7.92e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.08e-07  divErrNorms 7.44e-08 4.74e-01
step= 79  t= 2.00395000e+01  dt=5.0e-04  C= 1.83  UVW: 3  P: 5  eTimeStep= 2.71e-01s eTime= 2.37320e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 8.18e-04  resNorm 9.93e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.08e-07  divErrNorms 6.69e-08 4.74e-01
step= 80  t= 2.00400000e+01  dt=5.0e-04  C= 1.82  UVW: 3  P: 5  eTimeStep= 2.79e-01s eTime= 2.40108e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 9.11e-04  resNorm 9.63e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.08e-07  divErrNorms 5.94e-08 4.74e-01
step= 81  t= 2.00405000e+01  dt=5.0e-04  C= 1.81  UVW: 3  P: 5  eTimeStep= 2.80e-01s eTime= 2.42908e+01s
  P  : iter 006  resNorm00 1.37e-01  resNorm0 9.47e-04  resNorm 7.24e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.08e-07  divErrNorms 5.19e-08 4.74e-01
step= 82  t= 2.00410000e+01  dt=5.0e-04  C= 1.80  UVW: 3  P: 6  eTimeStep= 3.12e-01s eTime= 2.46026e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 8.49e-04  resNorm 8.31e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.08e-07  divErrNorms 4.45e-08 4.74e-01
step= 83  t= 2.00415000e+01  dt=5.0e-04  C= 1.80  UVW: 3  P: 5  eTimeStep= 2.81e-01s eTime= 2.48836e+01s
  P  : iter 004  resNorm00 1.37e-01  resNorm0 7.54e-04  resNorm 7.67e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.08e-07  divErrNorms 3.72e-08 4.74e-01
step= 84  t= 2.00420000e+01  dt=5.0e-04  C= 1.79  UVW: 3  P: 4  eTimeStep= 2.46e-01s eTime= 2.51300e+01s
  P  : iter 004  resNorm00 1.37e-01  resNorm0 8.89e-04  resNorm 9.72e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.08e-07  divErrNorms 2.99e-08 4.74e-01
step= 85  t= 2.00425000e+01  dt=5.0e-04  C= 1.78  UVW: 3  P: 4  eTimeStep= 2.38e-01s eTime= 2.53684e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 8.11e-03  resNorm 9.23e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.08e-07  divErrNorms 2.26e-08 4.74e-01
step= 86  t= 2.00430000e+01  dt=5.0e-04  C= 1.76  UVW: 3  P: 5  eTimeStep= 2.82e-01s eTime= 2.56504e+01s
  P  : iter 004  resNorm00 1.37e-01  resNorm0 1.02e-03  resNorm 8.96e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.08e-07  divErrNorms 1.54e-08 4.74e-01
step= 87  t= 2.00435000e+01  dt=5.0e-04  C= 1.75  UVW: 3  P: 4  eTimeStep= 2.44e-01s eTime= 2.58947e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 9.22e-04  resNorm 8.43e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.08e-07  divErrNorms 8.24e-09 4.74e-01
step= 88  t= 2.00440000e+01  dt=5.0e-04  C= 1.73  UVW: 3  P: 5  eTimeStep= 2.56e-01s eTime= 2.61512e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 1.13e-03  resNorm 9.89e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.09e-07  divErrNorms 1.13e-09 4.74e-01
step= 89  t= 2.00445000e+01  dt=5.0e-04  C= 1.71  UVW: 3  P: 5  eTimeStep= 2.79e-01s eTime= 2.64300e+01s
  P  : iter 006  resNorm00 1.37e-01  resNorm0 1.22e-03  resNorm 6.64e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.09e-07  divErrNorms 5.91e-09 4.74e-01
step= 90  t= 2.00450000e+01  dt=5.0e-04  C= 1.68  UVW: 3  P: 6  eTimeStep= 3.18e-01s eTime= 2.67482e+01s
  P  : iter 006  resNorm00 1.37e-01  resNorm0 1.44e-03  resNorm 8.76e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.09e-07  divErrNorms 1.29e-08 4.74e-01
step= 91  t= 2.00455000e+01  dt=5.0e-04  C= 1.68  UVW: 3  P: 6  eTimeStep= 3.15e-01s eTime= 2.70632e+01s
  P  : iter 006  resNorm00 1.37e-01  resNorm0 1.26e-03  resNorm 7.75e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.09e-07  divErrNorms 1.98e-08 4.74e-01
step= 92  t= 2.00460000e+01  dt=5.0e-04  C= 1.67  UVW: 3  P: 6  eTimeStep= 3.21e-01s eTime= 2.73845e+01s
  P  : iter 006  resNorm00 1.37e-01  resNorm0 1.24e-03  resNorm 8.69e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.09e-07  divErrNorms 2.67e-08 4.74e-01
step= 93  t= 2.00465000e+01  dt=5.0e-04  C= 1.66  UVW: 3  P: 6  eTimeStep= 3.17e-01s eTime= 2.77011e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 1.09e-03  resNorm 7.12e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.09e-07  divErrNorms 3.35e-08 4.74e-01
step= 94  t= 2.00470000e+01  dt=5.0e-04  C= 1.65  UVW: 3  P: 5  eTimeStep= 2.78e-01s eTime= 2.79786e+01s
  P  : iter 006  resNorm00 1.37e-01  resNorm0 1.07e-03  resNorm 6.34e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.09e-07  divErrNorms 4.03e-08 4.74e-01
step= 95  t= 2.00475000e+01  dt=5.0e-04  C= 1.67  UVW: 3  P: 6  eTimeStep= 3.14e-01s eTime= 2.82925e+01s
  P  : iter 006  resNorm00 1.37e-01  resNorm0 8.06e-03  resNorm 6.47e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.09e-07  divErrNorms 4.69e-08 4.74e-01
step= 96  t= 2.00480000e+01  dt=5.0e-04  C= 1.67  UVW: 3  P: 6  eTimeStep= 3.10e-01s eTime= 2.86026e+01s
  P  : iter 004  resNorm00 1.37e-01  resNorm0 9.89e-04  resNorm 8.40e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.09e-07  divErrNorms 5.36e-08 4.74e-01
step= 97  t= 2.00485000e+01  dt=5.0e-04  C= 1.64  UVW: 3  P: 4  eTimeStep= 2.17e-01s eTime= 2.88198e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 8.76e-04  resNorm 7.62e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.09e-07  divErrNorms 6.01e-08 4.74e-01
step= 98  t= 2.00490000e+01  dt=5.0e-04  C= 1.68  UVW: 3  P: 5  eTimeStep= 2.72e-01s eTime= 2.90917e+01s
  P  : iter 005  resNorm00 1.37e-01  resNorm0 7.80e-04  resNorm 7.51e-05
  UVW: iter 003  resNorm00 1.75e-01  resNorm0 1.75e-01  resNorm 2.09e-07  divErrNorms 6.66e-08 4.74e-01
step= 99  t= 2.00495000e+01  dt=5.0e-04  C= 1.73  UVW: 3  P: 5  eTimeStep= 2.81e-01s eTime= 2.93726e+01s
===================================================================
|                       Preconditioner | Niter |    Time (min/max) |
===================================================================
|  Chebyshev+Jacobi+Degree=1,(7,5,3,1) |   200 | 3.46e+00/3.47e+00 |
|    Chebyshev+Jacobi+Degree=1,(7,3,1) |   200 | 2.90e+00/2.91e+00 |
|  Chebyshev+Jacobi+Degree=2,(7,5,3,1) |   200 | 4.00e+00/4.03e+00 |
|    Chebyshev+Jacobi+Degree=2,(7,3,1) |   200 | 3.02e+00/3.29e+00 |
|  Chebyshev+Jacobi+Degree=3,(7,5,3,1) |   200 | 4.54e+00/4.71e+00 |
|    Chebyshev+Jacobi+Degree=3,(7,3,1) |   200 | 3.74e+00/3.78e+00 |
|     Chebyshev+ASM+Degree=1,(7,5,3,1) |   200 | 5.58e+00/5.97e+00 |
|       Chebyshev+ASM+Degree=1,(7,3,1) |   200 | 4.54e+00/4.57e+00 |
|     Chebyshev+ASM+Degree=2,(7,5,3,1) |   200 | 7.77e+00/7.78e+00 |
|       Chebyshev+ASM+Degree=2,(7,3,1) |   200 | 5.73e+00/5.79e+00 |
|     Chebyshev+ASM+Degree=3,(7,5,3,1) |   200 | 9.69e+00/9.70e+00 |
|       Chebyshev+ASM+Degree=3,(7,3,1) |   200 | 7.01e+00/7.07e+00 |
|     Chebyshev+RAS+Degree=1,(7,5,3,1) |   200 | 5.97e+00/6.01e+00 |
|       Chebyshev+RAS+Degree=1,(7,3,1) |   200 | 4.54e+00/4.57e+00 |
|     Chebyshev+RAS+Degree=2,(7,5,3,1) |   200 | 7.77e+00/7.79e+00 |
|       Chebyshev+RAS+Degree=2,(7,3,1) |   200 | 5.74e+00/5.80e+00 |
|     Chebyshev+RAS+Degree=3,(7,5,3,1) |   200 | 9.64e+00/9.73e+00 |
|       Chebyshev+RAS+Degree=3,(7,3,1) |   200 | 7.02e+00/7.10e+00 |
===================================================================

Fastest solver : Chebyshev+Jacobi+Degree=1,(7,3,1)
Unreasonable res0Norm!
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 6 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 3 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 18 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 8 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 42 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 1 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 19 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 7 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 20 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 9 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 43 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 21 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 45 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 23 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 10 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 44 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 2 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 22 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 46 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 30 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 66 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 11 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 47 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 31 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 5 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 67 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 32 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 68 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 33 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 48 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 70 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 24 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 34 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 69 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 4 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 71 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 35 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 12 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 49 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 54 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 25 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 55 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 56 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 50 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 57 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 26 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 13 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 58 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 59 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 51 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 27 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 14 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 52 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 28 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 15 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 53 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 29 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 17 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 16 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 36 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 37 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 60 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 38 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 61 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 39 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 62 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 40 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 63 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 41 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 64 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 65 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------

------------------------------------------------------------
Sender: LSF System <lsfadmin@batch5>
Subject: Job 1493508: <nekRS_peb1568_n2t2bnb> in cluster <summit> Exited

Job <nekRS_peb1568_n2t2bnb> was submitted from host <login5> by user <malachi> in cluster <summit> at Tue Oct  5 22:44:27 2021
Job was executed on host(s) <1*batch5>, in queue <batch>, as user <malachi> in cluster <summit> at Tue Oct  5 22:46:02 2021
                            <42*b02n14>
                            <42*b02n15>
                            <42*b02n16>
                            <42*b02n17>
                            <42*b02n18>
                            <42*b03n01>
                            <42*b03n02>
                            <42*b03n03>
                            <42*b03n04>
                            <42*b03n05>
                            <42*b03n06>
                            <42*b03n07>
</ccs/home/malachi> was used as the home directory.
</gpfs/alpine/scratch/malachi/csc262/siam-pp-22/pb1568/auto-fp32-12> was used as the working directory.
Started at Tue Oct  5 22:46:02 2021
Terminated at Tue Oct  5 22:53:33 2021
Results reported at Tue Oct  5 22:53:33 2021

The output (if any) is above this job summary.


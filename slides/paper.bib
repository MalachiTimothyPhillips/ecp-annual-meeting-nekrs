
@article{stiller_nonuniformly_2017,
	title = {Nonuniformly {Weighted} {Schwarz} {Smoothers} for {Spectral} {Element} {Multigrid}},
	volume = {72},
	issn = {0885-7474, 1573-7691},
	url = {http://link.springer.com/10.1007/s10915-016-0345-z},
	doi = {10.1007/s10915-016-0345-z},
	abstract = {A hybrid Schwarz/multigrid method for spectral element solvers to the Poisson equation in R2 is presented. It extends the additive Schwarz method studied by J. Lottes and P. Fischer (J. Sci. Comput. 24:45–78, 2005) by introducing nonuniform weight distributions based on the smoothed sign function. Using a V-cycle with only one pre-smoothing, the new method attains logarithmic convergence rates in the range from 1.2 to 1.9, which corresponds to residual reductions of almost two orders of magnitude. Compared to the original method, it reduces the iteration count by a factor of 1.5 to 3, leading to runtime savings of about 50 percent. In numerical experiments the method proved robust with respect to the mesh size and polynomial orders up to 32. Used as a preconditioner for the (inexact) CG method it is also suited for anisotropic meshes and easily extended to diﬀusion problems with variable coeﬃcients.},
	language = {en},
	number = {1},
	urldate = {2020-05-07},
	journal = {Journal of Scientific Computing},
	author = {Stiller, Jörg},
	month = jul,
	year = {2017},
	pages = {81--96},
	file = {Stiller - 2017 - Nonuniformly Weighted Schwarz Smoothers for Spectr.pdf:/home/malachi/Zotero/storage/I52GGFD6/Stiller - 2017 - Nonuniformly Weighted Schwarz Smoothers for Spectr.pdf:application/pdf},
}

@article{sundar_comparison_2015,
	title = {Comparison of multigrid algorithms for high-order continuous finite element discretizations},
	volume = {22},
	copyright = {Copyright © 2015 John Wiley \& Sons, Ltd.},
	issn = {1099-1506},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/nla.1979},
	doi = {10.1002/nla.1979},
	abstract = {We present a comparison of different multigrid approaches for the solution of systems arising from high-order continuous finite element discretizations of elliptic partial differential equations on complex geometries. We consider the pointwise Jacobi, the Chebyshev-accelerated Jacobi, and the symmetric successive over-relaxation smoothers, as well as elementwise block Jacobi smoothing. Three approaches for the multigrid hierarchy are compared: (1) high-order h-multigrid, which uses high-order interpolation and restriction between geometrically coarsened meshes; (2) p-multigrid, in which the polynomial order is reduced while the mesh remains unchanged, and the interpolation and restriction incorporate the different-order basis functions; and (3) a first-order approximation multigrid preconditioner constructed using the nodes of the high-order discretization. This latter approach is often combined with algebraic multigrid for the low-order operator and is attractive for high-order discretizations on unstructured meshes, where geometric coarsening is difficult. Based on a simple performance model, we compare the computational cost of the different approaches. Using scalar test problems in two and three dimensions with constant and varying coefficients, we compare the performance of the different multigrid approaches for polynomial orders up to 16. Overall, both h-multigrid and p-multigrid work well; the first-order approximation is less efficient. For constant coefficients, all smoothers work well. For variable coefficients, Chebyshev and symmetric successive over-relaxation smoothing outperform Jacobi smoothing. While all of the tested methods converge in a mesh-independent number of iterations, none of them behaves completely independent of the polynomial order. When multigrid is used as a preconditioner in a Krylov method, the iteration number decreases significantly compared with using multigrid as a solver. Copyright © 2015 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {4},
	urldate = {2020-09-05},
	journal = {Numerical Linear Algebra with Applications},
	author = {Sundar, Hari and Stadler, Georg and Biros, George},
	year = {2015},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/nla.1979},
	keywords = {algebraic multigrid, continuous finite elements, geometric multigrid, high-order, preconditioning, spectral elements},
	pages = {664--680},
	file = {Snapshot:/home/malachi/Zotero/storage/F427IKRJ/nla.html:text/html;Full Text PDF:/home/malachi/Zotero/storage/F6EK63EA/Sundar et al. - 2015 - Comparison of multigrid algorithms for high-order .pdf:application/pdf},
}

@article{loisel_hybrid_2008,
	title = {On {Hybrid} {Multigrid}-{Schwarz} {Algorithms}},
	abstract = {J. Lottes and P. Fischer (J. Sci. Comput. 24:45–78, 2005) studied many smoothers or preconditioners for hybrid Multigrid-Schwarz algorithms for the spectral element method. The behavior of several of these smoothers or preconditioners are analyzed in the present paper. Here it is shown that the Schwarz smoother that best performs in the above reference, is equivalent to a special case of the weighted restricted additive Schwarz, for which convergence analysis is presented. For other preconditioners which do not perform as well, examples and explanations are presented illustrating why this behavior may occur.},
	language = {en},
	journal = {J Sci Comput},
	author = {Loisel, Sébastien and Nabben, Reinhard and Szyld, Daniel B and Lottes, J and Fischer, P},
	year = {2008},
	pages = {11},
	file = {Loisel et al. - 2008 - On Hybrid Multigrid-Schwarz Algorithms.pdf:/home/malachi/Zotero/storage/B2EZUXY6/Loisel et al. - 2008 - On Hybrid Multigrid-Schwarz Algorithms.pdf:application/pdf},
}

@article{baker_multigrid_2011,
	title = {Multigrid {Smoothers} for {Ultraparallel} {Computing}},
	volume = {33},
	issn = {1064-8275, 1095-7197},
	url = {http://epubs.siam.org/doi/10.1137/100798806},
	doi = {10.1137/100798806},
	abstract = {This paper investigates the properties of smoothers in the context of algebraic multigrid (AMG) running on parallel computers with potentially millions of processors. The development of multigrid smoothers in this case is challenging, because some of the best relaxation schemes, such as the Gauss–Seidel (GS) algorithm, are inherently sequential. Based on the sharp two-grid multigrid theory from [R. D. Falgout and P. S. Vassilevski, SIAM J. Numer. Anal., 42 (2004), pp. 1669–1693] and [R. D. Falgout, P. S. Vassilevski, and L. T. Zikatanov, Numer. Linear Algebra Appl., 12 (2005), pp. 471–494] we characterize the smoothing properties of a number of practical candidates for parallel smoothers, including several C-F , polynomial, and hybrid schemes. We show, in particular, that the popular hybrid GS algorithm has multigrid smoothing properties which are independent of the number of processors in many practical applications, provided that the problem size per processor is large enough. This is encouraging news for the scalability of AMG on ultraparallel computers. We also introduce the more robust 1 smoothers, which are always convergent and have already proven essential for the parallel solution of some electromagnetic problems [T. Kolev and P. Vassilevski, J. Comput. Math., 27 (2009), pp. 604–623].},
	language = {en},
	number = {5},
	urldate = {2020-09-05},
	journal = {SIAM Journal on Scientific Computing},
	author = {Baker, Allison H. and Falgout, Robert D. and Kolev, Tzanio V. and Yang, Ulrike Meier},
	month = jan,
	year = {2011},
	pages = {2864--2887},
	file = {Baker et al. - 2011 - Multigrid Smoothers for Ultraparallel Computing.pdf:/home/malachi/Zotero/storage/HZ7RNWLE/Baker et al. - 2011 - Multigrid Smoothers for Ultraparallel Computing.pdf:application/pdf},
}

@article{swirydowicz_acceleration_2017,
	title = {Acceleration of tensor-product operations for high-order finite element methods},
	url = {http://arxiv.org/abs/1711.00903},
	abstract = {This paper is devoted to GPU kernel optimization and performance analysis of three tensorproduct operators arising in ﬁnite element methods. We provide a mathematical background to these operations and implementation details. Achieving close-to-the-peak performance for these operators requires extensive optimization because of the operators’ properties: low arithmetic intensity, tiered structure, and the need to store intermediate results inside the kernel. We give a guided overview of optimization strategies and we present a performance model that allows us to compare the eﬃcacy of these optimizations against an empirically calibrated rooﬂine.},
	language = {en},
	urldate = {2020-10-27},
	journal = {arXiv:1711.00903 [cs, math]},
	author = {Świrydowicz, Kasia and Chalmers, Noel and Karakus, Ali and Warburton, Timothy},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.00903},
	keywords = {Mathematics - Numerical Analysis, Computer Science - Mathematical Software, Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Performance},
	file = {Świrydowicz et al. - 2017 - Acceleration of tensor-product operations for high.pdf:/home/malachi/Zotero/storage/KBZ39R4G/Świrydowicz et al. - 2017 - Acceleration of tensor-product operations for high.pdf:application/pdf},
}

@article{austin_initial_2020,
	title = {Initial {Guesses} for {Sequences} of {Linear} {Systems} in a {GPU}-{Accelerated} {Incompressible} {Flow} {Solver}},
	url = {http://arxiv.org/abs/2009.10863},
	abstract = {We consider several methods for generating initial guesses when iteratively solving sequences of linear systems, showing that they can be implemented eﬃciently in GPU-accelerated PDE solvers, speciﬁcally solvers for incompressible ﬂow. We propose new initial guess methods based on stabilized polynomial extrapolation and compare them to the projection method of Fischer [15], showing that they are generally competitive with projection schemes despite requiring only half the storage and performing considerably less data movement and communication. Our implementations of these algorithms are freely available as part of the libParanumal collection of GPU-accelerated ﬂow solvers.},
	language = {en},
	urldate = {2020-11-02},
	journal = {arXiv:2009.10863 [cs, math]},
	author = {Austin, Anthony P. and Chalmers, Noel and Warburton, Tim},
	month = sep,
	year = {2020},
	note = {arXiv: 2009.10863},
	keywords = {Mathematics - Numerical Analysis, 65F10, 65M22},
	file = {Austin et al. - 2020 - Initial Guesses for Sequences of Linear Systems in.pdf:/home/malachi/Zotero/storage/WBJVV2RX/Austin et al. - 2020 - Initial Guesses for Sequences of Linear Systems in.pdf:application/pdf},
}

@inproceedings{stuben_multigrid_1982,
	address = {Berlin, Heidelberg},
	title = {Multigrid methods: {Fundamental} algorithms, model problem analysis and applications},
	isbn = {978-3-540-39544-7},
	booktitle = {Multigrid {Methods}},
	publisher = {Springer Berlin Heidelberg},
	author = {Stüben, Klaus and Trottenberg, Ulrich},
	editor = {Hackbusch, W. and Trottenberg, U.},
	year = {1982},
	pages = {1--176},
}

@article{lottes_hybrid_2005,
	title = {Hybrid {Multigrid}/{Schwarz} {Algorithms} for the {Spectral} {Element} {Method}},
	volume = {24},
	issn = {0885-7474, 1573-7691},
	url = {http://link.springer.com/10.1007/s10915-004-4787-3},
	doi = {10.1007/s10915-004-4787-3},
	abstract = {We study the performance of the multigrid method applied to spectral element (SE) discretizations of the Poisson and Helmholtz equations. Smoothers based on ﬁnite element (FE) discretizations, overlapping Schwarz methods, and point-Jacobi are considered in conjunction with conjugate gradient and GMRES acceleration techniques. It is found that Schwarz methods based on restrictions of the originating SE matrices converge faster than FE-based methods and that weighting the Schwarz matrices by the inverse of the diagonal counting matrix is essential to eﬀective Schwarz smoothing. Several of the methods considered achieve convergence rates comparable to those attained by classic multigrid on regular grids.},
	language = {en},
	number = {1},
	urldate = {2021-07-20},
	journal = {Journal of Scientific Computing},
	author = {Lottes, James W. and Fischer, Paul F.},
	month = jul,
	year = {2005},
	pages = {45--78},
	file = {Lottes and Fischer - 2005 - Hybrid MultigridSchwarz Algorithms for the Spectr.pdf:/home/malachi/Zotero/storage/ARVPW2XZ/Lottes and Fischer - 2005 - Hybrid MultigridSchwarz Algorithms for the Spectr.pdf:application/pdf},
}

@article{bello-maldonado_scalable_2019,
	title = {Scalable {Low}-{Order} {Finite} {Element} {Preconditioners} for {High}-{Order} {Spectral} {Element} {Poisson} {Solvers}},
	volume = {41},
	issn = {1064-8275, 1095-7197},
	url = {https://epubs.siam.org/doi/10.1137/18M1194997},
	doi = {10.1137/18M1194997},
	abstract = {Low-order finite element (FE) systems are considered as preconditioners for spectral element (SE) discretizations of the Poisson problem in canonical and complex domains. The FE matrices are based on the same mapped set of Gauss--Lobatto--Legendre (GLL) points as the SE discretization. Three different versions of the preconditioner based on combinations of the low-order stiffness and mass matrices are tested for 2D and 3D geometries. When building the preconditioning operators, a new meshing approach that allows elements to overlap without needing to fill out the volume of the mesh is explored and shown to be better than traditional schemes. These preconditioners are robust with respect to cell aspect ratio, demonstrate bounded iteration counts with hand p-refinement, and have lower iteration counts than scalable hybrid-Schwarz multigrid schemes currently used in production-level SE simulations. Overall costs for large-scale parallel applications are dependent on fast and robust solvers for the sparse FE systems. Algebraic multigrid is shown to offer a pathway to realizing a robust and fast preconditioning strategy in this context.},
	language = {en},
	number = {5},
	urldate = {2021-07-20},
	journal = {SIAM Journal on Scientific Computing},
	author = {Bello-Maldonado, Pedro D. and Fischer, Paul F.},
	month = jan,
	year = {2019},
	pages = {S2--S18},
	file = {Bello-Maldonado and Fischer - 2019 - Scalable Low-Order Finite Element Preconditioners .pdf:/home/malachi/Zotero/storage/WRB8E6IT/Bello-Maldonado and Fischer - 2019 - Scalable Low-Order Finite Element Preconditioners .pdf:application/pdf},
}

@article{fischer_overlapping_1997,
	title = {An {Overlapping} {Schwarz} {Method} for {Spectral} {Element} {Solution} of the {Incompressible} {Navier}–{Stokes} {Equations}},
	volume = {133},
	issn = {00219991},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0021999197956515},
	doi = {10.1006/jcph.1997.5651},
	abstract = {E cient solution of the Navier-Stokes equations in complex domains is dependent upon the availability of fast solvers for sparse linear systems. For unsteady incompressible ows, the pressure operator is the leading contributor to sti ness, as the characteristic propagation speed is in nite. In the context of operator splitting formulations, it is the pressure solve which is the most computationally challenging, despite its elliptic origins. We examine several preconditioners for the consistent L2 Poisson operator arising in the lPN ? lPN?2 spectral element formulation of the incompressible Navier-Stokes equations. We develop a nite element based additive Schwarz preconditioner using overlapping subdomains plus a coarse grid projection operator which is applied directly to the pressure on the interior Gauss points. For large two-dimensional problems this approach can yield as much as a ve-fold reduction in simulation time over previously employed methods based upon de ation.},
	language = {en},
	number = {1},
	urldate = {2021-07-20},
	journal = {Journal of Computational Physics},
	author = {Fischer, Paul F},
	month = may,
	year = {1997},
	pages = {84--101},
	file = {Fischer - 1997 - An Overlapping Schwarz Method for Spectral Element.pdf:/home/malachi/Zotero/storage/WJN4BMVT/Fischer - 1997 - An Overlapping Schwarz Method for Spectral Element.pdf:application/pdf},
}

@misc{noauthor_parallel_nodate,
	title = {Parallel {Newton}–{Chebyshev} polynomial preconditioners for the conjugate gradient method - {Bergamaschi} - - {Computational} and {Mathematical} {Methods} - {Wiley} {Online} {Library}},
	url = {https://onlinelibrary.wiley.com/doi/full/10.1002/cmm4.1153},
	urldate = {2021-09-09},
	file = {Parallel Newton–Chebyshev polynomial preconditioners for the conjugate gradient method - Bergamaschi - - Computational and Mathematical Methods - Wiley Online Library:/home/malachi/Zotero/storage/IG94DU2H/cmm4.html:text/html},
}

@article{adams_parallel_2003,
	title = {Parallel multigrid smoothing: polynomial versus {Gauss}–{Seidel}},
	volume = {188},
	issn = {00219991},
	shorttitle = {Parallel multigrid smoothing},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0021999103001943},
	doi = {10.1016/S0021-9991(03)00194-3},
	abstract = {Gauss-Seidel method is often the smoother of choice within multigrid applications. In the context of unstructured meshes, however, maintaining good parallel eﬃciency is diﬃcult with multiplicative iterative methods such as Gauss-Seidel. This leads us to consider alternative smoothers. We discuss the computational advantages of polynomial smoothers within parallel multigrid algorithms for positive deﬁnite symmetric systems. Two particular polynomials are considered: Chebyshev and a multilevel speciﬁc polynomial. The advantages of polynomial smoothing over traditional smoothers such as Gauss-Seidel are illustrated on several applications: Poisson’s equation, thin-body elasticity, and eddy current approximations to Maxwell’s equations. While parallelizing the Gauss-Seidel method typically involves a compromise between a scalable convergence rate and maintaining high ﬂop rates, polynomial smoothers achieve parallel scalable multigrid convergence rates without sacriﬁcing ﬂop rates. We show that, although parallel computers are the main motivation, polynomial smoothers are often surprisingly competitive with Gauss-Seidel smoothers on serial machines.},
	language = {en},
	number = {2},
	urldate = {2021-09-09},
	journal = {Journal of Computational Physics},
	author = {Adams, Mark and Brezina, Marian and Hu, Jonathan and Tuminaro, Ray},
	month = jul,
	year = {2003},
	pages = {593--610},
	file = {Adams et al. - 2003 - Parallel multigrid smoothing polynomial versus Ga.pdf:/home/malachi/Zotero/storage/7DAIYAJR/Adams et al. - 2003 - Parallel multigrid smoothing polynomial versus Ga.pdf:application/pdf},
}

@article{tomboulides_numerical_nodate,
	title = {Numerical {Simulation} of {Low} {Mach} {Number} {Reactive} {Flows}},
	language = {en},
	author = {Tomboulides, A G},
	pages = {29},
	file = {Tomboulides - Numerical Simulation of Low Mach Number Reactive F.pdf:/home/malachi/Zotero/storage/SZQTGILM/Tomboulides - Numerical Simulation of Low Mach Number Reactive F.pdf:application/pdf},
}

@book{varga_matrix_2000,
	address = {Berlin, Heidelberg},
	series = {Springer {Series} in {Computational} {Mathematics}},
	title = {Matrix {Iterative} {Analysis}},
	volume = {27},
	isbn = {978-3-642-05154-8 978-3-642-05156-2},
	url = {http://link.springer.com/10.1007/978-3-642-05156-2},
	language = {en},
	urldate = {2021-09-21},
	publisher = {Springer Berlin Heidelberg},
	author = {Varga, Richard S.},
	year = {2000},
	doi = {10.1007/978-3-642-05156-2},
	file = {Varga - 2000 - Matrix Iterative Analysis.pdf:/home/malachi/Zotero/storage/FK3FA6IJ/Varga - 2000 - Matrix Iterative Analysis.pdf:application/pdf},
}

@article{fischer_nekrs_2021,
	title = {{NekRS}, a {GPU}-{Accelerated} {Spectral} {Element} {Navier}-{Stokes} {Solver}},
	url = {http://arxiv.org/abs/2104.05829},
	abstract = {The development of NekRS, a GPU-oriented thermal-ﬂuids simulation code based on the spectral element method (SEM) is described. For performance portability, the code is based on the open concurrent compute abstraction and leverages scalable developments in the SEM code Nek5000 and in libParanumal, which is a library of high-performance kernels for high-order discretizations and PDE-based miniapps. Critical performance sections of the Navier–Stokes time advancement are addressed. Performance results on several platforms are presented, including scaling to 27,648 V100s on OLCF Summit, for calculations of up to 60B gridpoints.},
	language = {en},
	urldate = {2021-09-23},
	journal = {arXiv:2104.05829 [cs]},
	author = {Fischer, Paul and Kerkemeier, Stefan and Min, Misun and Lan, Yu-Hsiang and Phillips, Malachi and Rathnayake, Thilina and Merzari, Elia and Tomboulides, Ananias and Karakus, Ali and Chalmers, Noel and Warburton, Tim},
	month = apr,
	year = {2021},
	note = {arXiv: 2104.05829},
	keywords = {G.4, Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Performance, 35-04, D.0, F.2, G.2, I.6},
	file = {Fischer et al. - 2021 - NekRS, a GPU-Accelerated Spectral Element Navier-S.pdf:/home/malachi/Zotero/storage/DTTHJNAF/Fischer et al. - 2021 - NekRS, a GPU-Accelerated Spectral Element Navier-S.pdf:application/pdf},
}

@article{bello-maldonado_scalable_2019-1,
	title = {Scalable {Low}-{Order} {Finite} {Element} {Preconditioners} for {High}-{Order} {Spectral} {Element} {Poisson} {Solvers}},
	volume = {41},
	issn = {1064-8275, 1095-7197},
	url = {https://epubs.siam.org/doi/10.1137/18M1194997},
	doi = {10.1137/18M1194997},
	abstract = {Low-order finite element (FE) systems are considered as preconditioners for spectral element (SE) discretizations of the Poisson problem in canonical and complex domains. The FE matrices are based on the same mapped set of Gauss--Lobatto--Legendre (GLL) points as the SE discretization. Three different versions of the preconditioner based on combinations of the low-order stiffness and mass matrices are tested for 2D and 3D geometries. When building the preconditioning operators, a new meshing approach that allows elements to overlap without needing to fill out the volume of the mesh is explored and shown to be better than traditional schemes. These preconditioners are robust with respect to cell aspect ratio, demonstrate bounded iteration counts with hand p-refinement, and have lower iteration counts than scalable hybrid-Schwarz multigrid schemes currently used in production-level SE simulations. Overall costs for large-scale parallel applications are dependent on fast and robust solvers for the sparse FE systems. Algebraic multigrid is shown to offer a pathway to realizing a robust and fast preconditioning strategy in this context.},
	language = {en},
	number = {5},
	urldate = {2021-09-23},
	journal = {SIAM Journal on Scientific Computing},
	author = {Bello-Maldonado, Pedro D. and Fischer, Paul F.},
	month = jan,
	year = {2019},
	pages = {S2--S18},
	file = {Bello-Maldonado and Fischer - 2019 - Scalable Low-Order Finite Element Preconditioners .pdf:/home/malachi/Zotero/storage/BSNREIRN/Bello-Maldonado and Fischer - 2019 - Scalable Low-Order Finite Element Preconditioners .pdf:application/pdf},
}

@misc{noauthor_spectral_nodate,
	title = {Spectral {Methods} for {Problems} in {Complex} {Geometrics} {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/B9780125460507500149?token=3ACBEB4E305BAFC3116E9E18E10684FF01D0A68ECF29094322EA38F8E665EBC00EA26B8A3F3E34A2FF291C43AB8CBA4A&originRegion=us-east-1&originCreation=20210923222012},
	language = {en},
	urldate = {2021-09-23},
	doi = {10.1016/B978-0-12-546050-7.50014-9},
	file = {Snapshot:/home/malachi/Zotero/storage/QFW946E4/B9780125460507500149.html:text/html},
}

@incollection{parter_spectral_1979,
	title = {Spectral {Methods} for {Problems} in {Complex} {Geometrics}},
	isbn = {978-0-12-546050-7},
	url = {https://www.sciencedirect.com/science/article/pii/B9780125460507500149},
	abstract = {Publisher Summary This chapter presents some techniques that permit the efficient application of spectral methods to solve problems in nearly arbitrary geometries. The resulting methods are a viable alternative to finite difference and finite element methods for these problems. Spectral methods are particularly attractive for problems in several space dimensions in which high accuracy is required. These methods are based on representing the solution to a problem as a truncated series of smooth functions of the independent variables. Whereas finite element methods are based on expansions in local basis functions, spectral methods are based on expansions in global functions. Spectral methods are the extension of the standard technique of separation of variables to the solution of arbitrarily complicated problems. The chapter illustrates spectral methods for the simple one-dimensional heat equation. The chapter also discusses the difficulty caused by nontrivial boundary conditions and the difficulty of treating nonlinear and nonconstant coefficient terms. It then summarizes the properties of spectral methods for problems in simple geometries and explains how spectral methods can be extended to problems in complicated geometries.},
	booktitle = {Numerical {Methods} for {Partial} {Differential} {Equations}},
	publisher = {Academic Press},
	author = {Orszag, Steven A.},
	editor = {PARTER, SEYMOUR V.},
	year = {1979},
	doi = {https://doi.org/10.1016/B978-0-12-546050-7.50014-9},
	pages = {273--305},
}

@article{henson_boomeramg_2002,
	series = {Developments and {Trends} in {Iterative} {Methods} for {Large} {Systems} of {Equations} - in memorium {Rudiger} {Weiss}},
	title = {{BoomerAMG}: {A} parallel algebraic multigrid solver and preconditioner},
	volume = {41},
	issn = {0168-9274},
	shorttitle = {{BoomerAMG}},
	url = {https://www.sciencedirect.com/science/article/pii/S0168927401001155},
	doi = {10.1016/S0168-9274(01)00115-5},
	abstract = {Driven by the need to solve linear systems arising from problems posed on extremely large, unstructured grids, there has been a recent resurgence of interest in algebraic multigrid (AMG). AMG is attractive in that it holds out the possibility of multigrid-like performance on unstructured grids. The sheer size of many modern physics and simulation problems has led to the development of massively parallel computers, and has sparked much research into developing algorithms for them. Parallelizing AMG is a difficult task, however. While much of the AMG method parallelizes readily, the process of coarse-grid selection, in particular, is fundamentally sequential in nature. We have previously introduced a parallel algorithm [A.J. Cleary, R.D. Falgout, V.E. Henson, J.E. Jones, in: Proceedings of the Fifth International Symposium on Solving Irregularly Structured Problems in Parallel, Springer, New York, 1998] for the selection of coarse-grid points, based on modifications of certain parallel independent set algorithms and the application of heuristics designed to insure the quality of the coarse grids, and shown results from a prototype serial version of the algorithm. In this paper we describe an implementation of a parallel AMG code, using the algorithm of A.J. Cleary, R.D. Falgout, V.E. Henson, J.E. Jones [in: Proceedings of the Fifth International Symposium on Solving Irregularly Structured Problems in Parallel, Springer, New York, 1998] as well as other approaches to parallelizing the coarse-grid selection. We consider three basic coarsening schemes and certain modifications to the basic schemes, designed to address specific performance issues. We present numerical results for a broad range of problem sizes and descriptions, and draw conclusions regarding the efficacy of the method. Finally, we indicate the current directions of the research.},
	language = {en},
	number = {1},
	urldate = {2021-09-23},
	journal = {Applied Numerical Mathematics},
	author = {Henson, Van Emden and Yang, Ulrike Meier},
	month = apr,
	year = {2002},
	keywords = {Parallel computing, Algebraic multigrid},
	pages = {155--177},
	file = {ScienceDirect Full Text PDF:/home/malachi/Zotero/storage/KZIW2PUV/Henson and Yang - 2002 - BoomerAMG A parallel algebraic multigrid solver a.pdf:application/pdf},
}

@article{naumov_amgx_2015,
	title = {{AmgX}: {A} {Library} for {GPU} {Accelerated} {Algebraic} {Multigrid} and {Preconditioned} {Iterative} {Methods}},
	volume = {37},
	issn = {1064-8275},
	shorttitle = {{AmgX}},
	url = {https://epubs.siam.org/doi/abs/10.1137/140980260},
	doi = {10.1137/140980260},
	abstract = {The solution of large sparse linear systems arises in many applications, such as computational fluid dynamics and oil reservoir simulation. In realistic cases the matrices are often so large that they require large scale distributed parallel computing to obtain the solution of interest in a reasonable time. In this paper we discuss the design and implementation of the AmgX library, which provides drop-in GPU acceleration of distributed algebraic multigrid (AMG) and preconditioned iterative methods. The AmgX library implements both classical and aggregation-based AMG methods with different selector and interpolation strategies, along with a variety of smoothers and preconditioners, including block-Jacobi, Gauss--Seidel, and incomplete-LU factorization. The library contains many of the standard and flexible preconditioned Krylov subspace iterative methods, which can be combined with any of the available multigrid methods or simpler preconditioners. The parallelism in the aggregation scheme exploits parallel graph matching techniques, while the smoothers and preconditioners often rely on parallel graph coloring algorithms. The AMG algorithm implemented in the AmgX library achieves \$2\$--\$5{\textbackslash}times\$ speedup on a single GPU against a competitive implementation on the CPU. As will be shown in the numerical experiments section, both setup and solve phases scale well across multiple nodes, sustaining this performance advantage.},
	number = {5},
	urldate = {2021-09-23},
	journal = {SIAM Journal on Scientific Computing},
	author = {Naumov, M. and Arsaev, M. and Castonguay, P. and Cohen, J. and Demouth, J. and Eaton, J. and Layton, S. and Markovskiy, N. and Reguly, I. and Sakharnykh, N. and Sellappan, V. and Strzodka, R.},
	month = jan,
	year = {2015},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	keywords = {15, 35, 65, 68, 76, aggregation, AMG, CFD, classical, CUDA, GPU, graph coloring, graph matching, ILU, level-scheduling, MPI, preconditioned iterative methods, reservoir simulation},
	pages = {S602--S626},
}

@article{canuto_finite-element_2010,
	title = {Finite-{Element} {Preconditioning} of {G}-{NI} {Spectral} {Methods}},
	volume = {31},
	issn = {1064-8275},
	url = {https://epubs.siam.org/doi/abs/10.1137/090746367},
	doi = {10.1137/090746367},
	abstract = {Several old and new finite-element preconditioners for nodal-based spectral discretizations of \$-{\textbackslash}Delta u=f\$ in the domain \${\textbackslash}Omega=(-1,1){\textasciicircum}d\$ (\$d=2\$ or 3), with Dirichlet or Neumann boundary conditions, are considered and compared in terms of both condition number and computational efficiency. The computational domain covers the case of classical single-domain spectral approximations (see [C. Canuto et al., Spectral Methods. Fundamentals in Single Domains, Springer, Heidelberg, 2006]), as well as that of more general spectral-element methods in which the preconditioners are expressed in terms of local (upon every element) algebraic solvers. The primal spectral approximation is based on the Galerkin approach with numerical integration (G-NI) at the Legendre–Gauss–Lobatto (LGL) nodes in the domain. The preconditioning matrices rely on either \${\textbackslash}mathbb\{P\}\_1\$, \${\textbackslash}mathbb\{Q\}\_1\$, or \${\textbackslash}mathbb\{Q\}\_\{1,NI\}\$ (i.e., with numerical integration) finite elements on meshes whose vertices coincide with the LGL nodes used for the spectral approximation. The analysis highlights certain preconditioners, which yield the solution at an overall cost proportional to \$N{\textasciicircum}\{d+1\}\$, where N denotes the polynomial degree in each direction.},
	number = {6},
	urldate = {2021-09-24},
	journal = {SIAM Journal on Scientific Computing},
	author = {Canuto, Claudio and Gervasio, Paola and Quarteroni, Alfio},
	month = jan,
	year = {2010},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	keywords = {preconditioned iterative methods, 65F10, 65N35, elliptic equations, finite elements, spectral method},
	pages = {4422--4451},
}

@article{olson_algebraic_2007,
	title = {Algebraic {Multigrid} {Preconditioning} of {High}-{Order} {Spectral} {Elements} for {Elliptic} {Problems} on a {Simplicial} {Mesh}},
	volume = {29},
	issn = {1064-8275},
	url = {https://epubs.siam.org/doi/abs/10.1137/060663465},
	doi = {10.1137/060663465},
	abstract = {Algebraic multigrid is investigated as a solver for linear systems that arise from high-order spectral element discretizations. An algorithm is introduced that utilizes the efficiency of low-order finite elements to precondition the high-order method in a multilevel setting. In particular, the efficacy of this approach is highlighted on simplexes in two and three dimensions with nodal spectral elements up to order \$n=11\$. Additionally, a hybrid preconditioner is also developed for use with discontinuous spectral element methods. The latter approach is verified for the discontinuous Galerkin method on elliptic problems.},
	number = {5},
	urldate = {2021-09-24},
	journal = {SIAM Journal on Scientific Computing},
	author = {Olson, Luke},
	month = jan,
	year = {2007},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	keywords = {algebraic multigrid, 65N15, 65N30, 65N55, discontinuous Galerkin, spectral element},
	pages = {2189--2209},
}

@techreport{kolev_ceed_2021,
	title = {{CEED} {ECP} {Milestone} {Report}: {High}-order algorithmic developments and optimizations for large-scale {GPU}-accelerated simulations},
	shorttitle = {{CEED} {ECP} {Milestone} {Report}},
	url = {https://zenodo.org/record/4672664},
	abstract = {ECP Milestone Report High-order algorithmic developments and optimizations for large-scale GPU-accelerated simulations WBS 2.2.6.06, Milestone CEED-MS36},
	language = {eng},
	urldate = {2021-09-27},
	institution = {Zenodo},
	author = {Kolev, Tzanio and Fischer, Paul and Austin, Anthony P. and Barker, Andrew T. and Beams, Natalie and Brown, Jed and Camier, Jean-Sylvain and Chalmers, Noel and Dobrev, Veselin and Dudouit, Yohann and Ghaffari, Leila and Kerkemeier, Stefan and Lan, Yu-Hsiang and Merzari, Elia and Min, Misun and Pazner, Will and Ratnayaka, Thilina and Shephard, Mark S. and Siboni, Morteza H. and Smith, Cameron W. and Thompson, Jeremy L. and Tomov, Stanimire and Warburton, Tim},
	month = mar,
	year = {2021},
	doi = {10.5281/zenodo.4672664},
	file = {Zenodo Full Text PDF:/home/malachi/Zotero/storage/SMUIF3QB/Kolev et al. - 2021 - CEED ECP Milestone Report High-order algorithmic .pdf:application/pdf},
}

@article{sanal_kumar_theoretical_2021,
	title = {The theoretical prediction of the boundary-layer-blockage and external flow choking at moving aircraft in ground effects},
	volume = {33},
	issn = {1070-6631, 1089-7666},
	url = {https://aip.scitation.org/doi/10.1063/5.0040440},
	doi = {10.1063/5.0040440},
	language = {en},
	number = {3},
	urldate = {2021-09-27},
	journal = {Physics of Fluids},
	author = {Sanal Kumar, V. R. and Saravanan, Vignesh and Srinivasan, Vivek and Ganesh Shankar, S. and Mani, Sivabalan and Sankar, Vigneshwaran and Krishnamoorthy, Dhanalakshmi and Natarajan, Deepak and Mohamed Rafic, Sulthan Ariff Rahman and Baskaran, Roshan Vignesh and Chandrasekaran, Nichith and Natarajan, Vishnu and Sukumaran, Ajith and Doddi, Hema Sai Nagaraju and Padmanabhan, Sathyan and Balasubramaniam, Gowtham and Saravanan, A. and Santhosh Kumar, N. and Lenin, C. and Mohamed Imran Khan, A. and Saravanan, M. and Balakrishnan, R. and Balachandru, R. and Murugesan, Mohanraj and Venkatesan, Dharni Vasudhevan and Shanjay, K. E. and Sujith Kumar, H. and Abhilash, N. A. and Aswin Ram, D. and Janardhanan, Vignesh and Krishnaraj, K and Gunasekaran, Sandeep and Karunakaran, Sabarinath and Vineeshwar, S. and Mariappan, Amrith and Kiridharan, R. and Sabarinathan, R. and Ajith Kumar, M. and Pradeep, Rahul and Thianesh, U. K. and Rajaram Perumal, M. and Sumanth Eswar, K. S. and Rajesh, M.},
	month = mar,
	year = {2021},
	pages = {036108},
	file = {Sanal Kumar et al. - 2021 - The theoretical prediction of the boundary-layer-b.pdf:/home/malachi/Zotero/storage/QZ6TQM5C/Sanal Kumar et al. - 2021 - The theoretical prediction of the boundary-layer-b.pdf:application/pdf},
}

@misc{noauthor_direct_nodate,
	title = {Direct numerical simulation of the two-dimensional speed bump flow at increasing {Reynolds} numbers {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0142727X21000709?token=58BDE5FCE297C7A5BAD3FDB7610A1107EF8E9275802058C03ED285C139CD30E3982FFA036D608B703257D8721EEEE177&originRegion=us-east-1&originCreation=20210927050841},
	language = {en},
	urldate = {2021-09-27},
	doi = {10.1016/j.ijheatfluidflow.2021.108840},
	file = {Snapshot:/home/malachi/Zotero/storage/Y8IEWBJZ/S0142727X21000709.html:text/html},
}

@article{kershaw_differencing_1981,
	title = {Differencing of the diffusion equation in {Lagrangian} hydrodynamic codes},
	volume = {39},
	number = {2},
	journal = {Journal of Computational Physics},
	author = {Kershaw, David S},
	year = {1981},
	note = {Publisher: Elsevier},
	pages = {375--395},
}

@book{deville_high-order_2002,
	title = {High-order methods for incompressible fluid flow},
	volume = {9},
	publisher = {Cambridge university press},
	author = {Deville, Michel O and Fischer, Paul F and Fischer, Paul F and Mund, EH},
	year = {2002},
}

@article{fischer_projection_1998,
	title = {Projection techniques for iterative solution of {Ax}= b with successive right-hand sides},
	volume = {163},
	number = {1-4},
	journal = {Computer methods in applied mechanics and engineering},
	author = {Fischer, Paul F},
	year = {1998},
	note = {Publisher: Elsevier},
	pages = {193--204},
	file = {Fischer - 1998 - Projection techniques for iterative solution of Ax.pdf:/home/malachi/Zotero/storage/HH2MV7H5/Fischer - 1998 - Projection techniques for iterative solution of Ax.pdf:application/pdf},
}

@article{st-cyr_optimized_2007,
	title = {Optimized multiplicative, additive, and restricted additive {Schwarz} preconditioning},
	volume = {29},
	number = {6},
	journal = {SIAM Journal on Scientific Computing},
	author = {St-Cyr, Amik and Gander, Martin J and Thomas, Stephen J},
	year = {2007},
	note = {Publisher: SIAM},
	pages = {2402--2425},
}

@article{shur_direct_2021,
	title = {Direct numerical simulation of the two-dimensional speed bump flow at increasing {Reynolds} numbers},
	volume = {90},
	journal = {International Journal of Heat and Fluid Flow},
	author = {Shur, Mikhail L and Spalart, Philippe R and Strelets, Mikhail Kh and Travin, Andrey K},
	year = {2021},
	note = {Publisher: Elsevier},
	pages = {108840},
}

@misc{noauthor_center_nodate,
	title = {Center for {Efficient} {Exascale} {Discretizations}},
	url = {https://ceed.exascaleproject.org/bps/},
	urldate = {2021-10-06},
	file = {Center for Efficient Exascale Discretizations:/home/malachi/Zotero/storage/VMKNWW7G/bps.html:text/html},
}

@misc{noauthor_interface_nodate,
	title = {Interface {Concepts} — {libCEED} 0.9.0 documentation},
	url = {https://libceed.readthedocs.io/en/latest/libCEEDapi/},
	urldate = {2021-10-06},
	file = {Interface Concepts — libCEED 0.9.0 documentation:/home/malachi/Zotero/storage/R4ELXJC4/libCEEDapi.html:text/html},
}

@article{fischer_highly_2021,
	title = {Highly {Optimized} {Full}-{Core} {Reactor} {Simulations} on {Summit}},
	url = {http://arxiv.org/abs/2110.01716},
	abstract = {Nek5000/RS is a highly-performant open-source spectral element code for simulation of incompressible and low-Mach ﬂuid ﬂow, heat transfer, and combustion with a particular focus on turbulent ﬂows in complex domains. It is based on high-order discretizations that realize the same (or lower) cost per gridpoint as traditional low-order methods. Stateof-the-art multilevel preconditioners, efﬁcient high-order time-splitting methods, and runtime-adaptive communication strategies are built on a fast OCCA-based kernel library, libParanumal, to provide scalability and portability across the spectrum of current and future high-performance computing platforms. On Summit, Nek5000/RS has recently achieved an milestone in the simulation of nuclear reactors: the ﬁrst full-core computational ﬂuid dynamics simulations of reactor cores, including pebble beds with {\textgreater} 350,000 pebbles and 98M elements advanced in less than 0.25 seconds per Navier-Stokes timestep. With carefully tuned algorithms, it is possible to simulate a single ﬂow-through time for a full reactor core in less than six hours on all of Summit.},
	language = {en},
	urldate = {2021-10-07},
	journal = {arXiv:2110.01716 [physics]},
	author = {Fischer, Paul and Merzari, Elia and Min, Misun and Kerkemeier, Stefan and Lan, Yu-Hsiang and Phillips, Malachi and Rathnayake, Thilina and Novak, April and Gaston, Derek and Chalmers, Noel and Warburton, Tim},
	month = oct,
	year = {2021},
	note = {arXiv: 2110.01716},
	keywords = {G.4, 35-04, D.0, F.2, G.2, I.6, J.2, Physics - Computational Physics},
	file = {Fischer et al. - 2021 - Highly Optimized Full-Core Reactor Simulations on .pdf:/home/malachi/Zotero/storage/R48BNLNC/Fischer et al. - 2021 - Highly Optimized Full-Core Reactor Simulations on .pdf:application/pdf},
}
@article{Kronbichler2019,
  author       = {Kronbichler, Martin and Ljungkvist, Karl},
  doi          = {10.1145/3322813},
  journal      = {ACM Transactions on Parallel Computing},
  month        = {05},
  number       = {1},
  pages        = {1--32},
  title        = {Multigrid for matrix-free high-order finite element
                  computations on graphics processors}, 
  volume       = {6},
  year         = {2019},
}
@book{dfm02,
   author = "Deville, M.O. and P.F. Fischer and E.H. Mund",
   title = "High-order methods for incompressible fluid flow",
   publisher = "Cambridge University Press",
   address = "Cambridge",
   year = "2002"}
@article{canuto10,
   author = "Canuto, C. and P. Gervasio and A. Quarteroni",
   title="Finite-element preconditioning of {G-NI} spectral methods",
   journal = siamsc,
   volume = "31",
   year = "2010",
   pages = "4422--44251"}
@ARTICLE{ras99,
    author = {Xiao-chuan Cai and Marcus Sarkis},
    title = {A restricted additive {S}chwarz preconditioner for general sparse linear systems},
    journal = {SIAM J. Sci. Comput},
    year = {1999},
    volume = {21},
    pages = {792--797}
}
@inproceedings{fischer04,
   author = "Fischer, P.F. and J.W. Lottes",
   title = "Hybrid {Schwarz}-Multigrid Methods for the Spectral Element Method:
	    Extensions to {Navier-Stokes}",
   booktitle= "Domain Decomposition Methods in Science and Engineering Series",
   editor = "Kornhuber, R. and R. Hoppe and J. P{\'e}riaux and O. Pironneau
	     and O. Widlund and J. Xu",
   publisher = "Springer, Berlin",
   year = "2004"}
@article{zhukov_multigrid_2015,
  title = {Multigrid method for anisotropic diffusion equations based on adaptive {Chebyshev} smoothers},
  volume = {7},
  issn = {2070-0482, 2070-0490},
  url = {http://link.springer.com/10.1134/S2070048215020118},
  doi = {10.1134/S2070048215020118},
  abstract = {We propose an efficient multigrid algorithm for solving anisotropic elliptic difference equa tions. The algorithm is based on using Chebyshev’s explicit iterations at smoothing stages and in solv ing coarse grid equations. We have developed a procedure for adapting smoothers to anisotropy and present examples, which show that adaptation improves the efficiency of the multigrid method and scalability of the parallel code.},
  language = {en},
  number = {2},
  urldate = {2021-10-08},
  journal = {Mathematical Models and Computer Simulations},
  author = {Zhukov, V. T. and Novikova, N. D. and Feodoritova, O. B.},
  month = mar,
  year = {2015},
  pages = {117--127},
  file = {Zhukov et al. - 2015 - Multigrid method for anisotropic diffusion equatio.pdf:/home/malachi/Zotero/storage/F7SJJSHK/Zhukov et al. - 2015 - Multigrid method for anisotropic diffusion equatio.pdf:application/pdf},
}

@MISC{libp,
      author = "Chalmers, N. and Karakus, A. and Austin, A. P. and Swirydowicz, K. and Warburton, T.",
      title = "{libParanumal}: a performance portable high-order finite element library",
      year = "2020",
      url = "https://github.com/paranumal/libparanumal",
      doi = "10.5281/zenodo.4004744",
      note = "Release 0.4.0"
      }

@article{medina2014occa,
  title={OCCA: A unified approach to multi-threading languages},
  author={Medina, David S and St-Cyr, Amik and Warburton, Tim},
  journal={arXiv preprint arXiv:1403.0968},
  year={2014}
}
@article{thompson2021local,
  title={Local Fourier Analysis of P-Multigrid for High-Order Finite Element Operators},
  author={Thompson, Jeremy L and Brown, Jed and He, Yunhui},
  journal={arXiv preprint arXiv:2108.01751},
  year={2021}
}
@article{brown_tuning_2021,
	title = {Tuning {Multigrid} {Methods} with {Robust} {Optimization} and {Local} {Fourier} {Analysis}},
	volume = {43},
	issn = {1064-8275, 1095-7197},
	url = {https://epubs.siam.org/doi/10.1137/19M1308669},
	doi = {10.1137/19M1308669},
	abstract = {Local Fourier analysis is a useful tool for predicting and analyzing the performance of many efficient algorithms for the solution of discretized PDEs, such as multigrid and domain decomposition methods. The crucial aspect of local Fourier analysis is that it can be used to minimize an estimate of the spectral radius of a stationary iteration, or the condition number of a preconditioned system, in terms of a symbol representation of the algorithm. In practice, this is a ``minimax"" problem, minimizing with respect to solver parameters the appropriate measure of solver work, which involves maximizing over the Fourier frequency. Often, several algorithmic parameters may be determined by local Fourier analysis in order to obtain efficient algorithms. Analytical solutions to minimax problems are rarely possible beyond simple problems; the status quo in local Fourier analysis involves grid sampling, which is prohibitively expensive in high dimensions. In this paper, we propose and explore optimization algorithms to solve these problems efficiently. Several examples, with known and unknown analytical solutions, are presented to show the effectiveness of these approaches.},
	language = {en},
	number = {1},
	urldate = {2021-10-21},
	journal = {SIAM Journal on Scientific Computing},
	author = {Brown, Jed and He, Yunhui and MacLachlan, Scott and Menickelly, Matt and Wild, Stefan M.},
	month = jan,
	year = {2021},
	pages = {A109--A138},
	file = {Brown et al. - 2021 - Tuning Multigrid Methods with Robust Optimization .pdf:files/459/Brown et al. - 2021 - Tuning Multigrid Methods with Robust Optimization .pdf:application/pdf},
}
@inproceedings{imakura_auto-tuning_2012,
	title = {An {Auto}-{Tuning} {Technique} of the {Weighted} {Jacobi}-{Type} {Iteration} {Used} for {Preconditioners} of {Krylov} {Subspace} {Methods}},
	doi = {10.1109/MCSoC.2012.29},
	abstract = {The Jacobi iteration is often used for preconditioners with high parallel efficiency of Krylov subspace methods to solve very large linear systems. However, these preconditioners do not always show great improvement of the convergence rate, because of the strict convergence condition and the poor convergence property of the Jacobi iteration. In order to resolve this difficulty, we recently introduced the weighted Jacobi-type iteration which has a weight parameter and a scaling diagonal matrix, and proposed the optimization technique for its weight parameter. As its efficient development, in this paper, we propose an auto-tuning technique not only for the weight parameter but also for the scaling diagonal matrix of the weighted Jacobi-type iteration used for preconditioners. The numerical experiments indicate that our auto-tuning technique is well played to solve very large linear systems.},
	booktitle = {2012 {IEEE} 6th {International} {Symposium} on {Embedded} {Multicore} {SoCs}},
	author = {Imakura, Akira and Sakurai, Tetsuya and Sumiyoshi, Kohsuke and Matsufuru, Hideo},
	month = sep,
	year = {2012},
	keywords = {Auto-tuning technique, Gold, Krylov subspace methods, Multicore processing, Preconditioners, System-on-a-chip, Weighted Jacobi-type iteration},
	pages = {183--190},
	file = {IEEE Xplore Full Text PDF:files/505/Imakura et al. - 2012 - An Auto-Tuning Technique of the Weighted Jacobi-Ty.pdf:application/pdf;IEEE Xplore Abstract Record:files/506/6354697.html:text/html},
}
@article{lan_all-hex_2021,
	title = {All-{Hex} {Meshing} {Strategies} {For} {Densely} {Packed} {Spheres}},
	abstract = {We develop an all-hex meshing strategy for the interstitial space in beds of densely packed spheres that is tailored to turbulent ﬂow simulations based on the spectral element method (SEM). The SEM achieves resolution through elevated polynomial order N and requires two to three orders of magnitude fewer elements than standard ﬁnite element approaches do. These reduced element counts place stringent requirements on mesh quality and conformity. Our meshing algorithm is based on a Voronoi decomposition of the sphere centers. Facets of the Voronoi cells are tessellated into quads that are swept to the sphere surface to generate a high-quality base mesh. Reﬁnements to the algorithm include edge collapse to remove slivers, node insertion to balance resolution, localized reﬁnement in the radial direction about each sphere, and mesh optimization. We demonstrate geometries with 102–105 spheres using ≈ 300 elements per sphere (for three radial layers), along with mesh quality metrics, timings, ﬂow simulations, and solver performance.},
	language = {en},
	urldate = {2021-12-06},
	journal = {Proceedings of the 29th International Meshing Roundtable},
	author = {Lan, Yu-Hsiang and Fischer, Paul and Merzari, Elia and Min, Misun},
	month = jun,
	year = {2021},
	doi = {10.5281/zenodo.5551173},
	keywords = {D.0, F.2, I.6, J.2, 76-10, Computer Science - Computational Engineering, Finance, and Science},
	file = {Lan et al. - 2021 - All-Hex Meshing Strategies For Densely Packed Sphe.pdf:files/508/Lan et al. - 2021 - All-Hex Meshing Strategies For Densely Packed Sphe.pdf:application/pdf},
	pages = {293--305},
}
@inproceedings{yamada2018preconditioner,
  title={Preconditioner auto-tuning using deep learning for sparse iterative algorithms},
  author={Yamada, Kenya and Katagiri, Takahiro and Takizawa, Hiroyuki and Minami, Kazuo and Yokokawa, Mitsuo and Nagai, Toru and Ogino, Masao},
  booktitle={2018 Sixth International Symposium on Computing and Networking Workshops (CANDARW)},
  pages={257--262},
  year={2018},
  organization={IEEE}
}
@article{yuan2020spectral,
  title={Spectral element applications in complex nuclear reactor geometries: Tet-to-hex meshing},
  author={Yuan, Haomin and Yildiz, Mustafa A and Merzari, Elia and Yu, Yiqi and Obabko, Aleksandr and Botha, Gerrit and Busco, Giacomo and Hassan, Yassin A and Nguyen, Duy Thien},
  journal={Nuclear Engineering and design},
  volume={357},
  pages={110422},
  year={2020},
  publisher={Elsevier}
}
@article{mittal2019mesh,
  title={Mesh smoothing for the spectral element method},
  author={Mittal, Ketan and Fischer, Paul},
  journal={Journal of Scientific Computing},
  volume={78},
  number={2},
  pages={1152--1173},
  year={2019},
  publisher={Springer}
}

% META: this paper
@inbook{phillips-tuning-2022,
author = {Malachi Phillips and Stefan Kerkemeier and Paul Fischer},
title = {Tuning Spectral Element Preconditioners for Parallel Scalability on GPUs},
booktitle = {Proceedings of the 2022 SIAM Conference on Parallel Processing for Scientific Computing (PP)},
chapter = {},
pages = {37-48},
doi = {10.1137/1.9781611977141.4},
URL = {https://epubs.siam.org/doi/abs/10.1137/1.9781611977141.4},
eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611977141.4},
    abstract = { Abstract The Poisson pressure solve resulting from the spectral element discretization of the incompressible Navier-Stokes equation requires fast, robust, and scalable preconditioning. In the current work, a parallel scaling study of Chebyshevaccelerated Schwarz and Jacobi preconditioning schemes is presented, with special focus on GPU architectures, such as OLCF's Summit. Convergence properties of the Chebyshevaccelerated schemes are compared with alternative methods, such as low-order preconditioners combined with algebraic multigrid. Performance and scalability results are presented for a variety of preconditioner and solver settings. The authors demonstrate that Chebyshev-accelerated-Schwarz methods provide a robust and effective smoothing strategy when using p-multigrid as a preconditioner in a Krylovsubspace projector. The variety of cases to be addressed, on a wide range of processor counts, suggests that performance can be enhanced by automated run-time selection of the preconditioner and associated parameters. }
}
